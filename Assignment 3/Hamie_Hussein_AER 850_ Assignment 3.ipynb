{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Hussein Hamie\n",
    "500876254\n",
    "AER 850 Machine Learning\n",
    "Assignment 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Importing Libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "tf.config.experimental.enable_tensor_float_32_execution(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading in Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "baselineDE = pd.read_excel('/mnt/d/AER 850 Machine Learning/baseline.xlsx',sheet_name=\"Baseline DE\")\n",
    "\n",
    "baseline007DE = pd.read_excel('/mnt/d/AER 850 Machine Learning/baseline.xlsx',sheet_name=\"0.007 DE\")\n",
    "\n",
    "baseline021DE = pd.read_excel('/mnt/d/AER 850 Machine Learning/baseline.xlsx',sheet_name=\"0.021 DE\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "baselineDE.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "baselineDE.insert(0, 'Fault', 0)\n",
    "baselineDE = baselineDE.rename(columns={'Baseline 0HP DE X97':'0HP','Baseline 1HP DE X98':'1HP','Baseline 2HP DE X99':'2HP','Baseline 3HP DE':'3HP'})\n",
    "baselineDE.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "baseline007DE.insert(0,'Fault',1)\n",
    "baseline007DE = baseline007DE.rename(columns={'12K 0.007\" 0HP':'0HP','12K 0.007\" 1HP':'1HP','12K 0.007\" 2HP':'2HP','12K 0.007\" 3HP':'3HP'})\n",
    "baseline007DE.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "baseline021DE.insert(0,'Fault',1)\n",
    "baseline021DE = baseline021DE.rename(columns={'12K 0.021\" 0HP':'0HP','12K 0.021\" 1HP':'1HP','12K 0.021\" 2HP':'2HP','12K 0.021\" 3HP':'3HP'})\n",
    "baseline021DE.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "faultdata = pd.concat([baselineDE,baseline007DE,baseline021DE])\n",
    "faultdata.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "faultdatashuffled = faultdata.sample(frac=1,random_state = 42)\n",
    "faultdatashuffled.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_columns(dataframe_cols):\n",
    "    fig, axes = plt.subplots(nrows=3, ncols=4, figsize=(16, 9), sharey=True)\n",
    "    colors = plt.cm.get_cmap('Set1', len(axes[0]))\n",
    "    for i, ax in enumerate(axes.flatten()):\n",
    "        if i < len(dataframe_cols):\n",
    "            col = dataframe_cols[i]\n",
    "            ax.scatter(col.index, col.values, s=0.05, color=colors(i % len(axes[0])))\n",
    "            ax.set_title(col.name)\n",
    "        else:\n",
    "            ax.set_visible(False)\n",
    "    for i, ax in enumerate(axes[:, 0]):\n",
    "        if i == 0:\n",
    "            ax.set_ylabel('normal', rotation=0, fontsize='large', labelpad=40)\n",
    "        elif i == 1:\n",
    "            ax.set_ylabel('0.0071 fault', rotation=0, fontsize='large', labelpad=40)\n",
    "        elif i == 2:\n",
    "            ax.set_ylabel('0.021 fault', rotation=0, fontsize='large', labelpad=40)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "listsofdatas= [baselineDE['0HP'],baselineDE['1HP'],baselineDE['2HP'],baselineDE['3HP'],baseline007DE['0HP'],baseline007DE['1HP'],baseline007DE['2HP'],baseline007DE['3HP'],baseline021DE['0HP'],baseline021DE['1HP'],baseline021DE['2HP'],baseline021DE['3HP']]\n",
    "plot_columns(listsofdatas)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def transpose_and_add_fault_column(df,fault):\n",
    "    # drop 'Fault' column (if it exists)\n",
    "    if 'Fault' in df.columns:\n",
    "        df = df.drop(columns=['Fault'])\n",
    "\n",
    "    # transpose DataFrame\n",
    "    df = pd.DataFrame(df.values.T, index=df.columns, columns=df.index)\n",
    "\n",
    "    # add 'Fault' column with all values set to the fault\n",
    "    # df.insert(0, 'Fault', fault)\n",
    "\n",
    "    # return the modified DataFrame\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "outputs": [],
   "source": [
    "df = pd.concat([trans_baselineDE, trans_baseline007DE, trans_baseline021DE],axis=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121265\n"
     ]
    }
   ],
   "source": [
    "mask = df.isna()\n",
    "first_nan_index = mask.any(axis=0).idxmax()\n",
    "print(first_nan_index)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "outputs": [
    {
     "data": {
      "text/plain": "       0         1         2         3         4         5         6       \\\n0HP  0.053197  0.088662  0.099718  0.058621 -0.004590 -0.056952 -0.071764   \n1HP  0.145667  0.097796  0.054856  0.036982  0.054445  0.021162 -0.003698   \n2HP  0.064254  0.063002 -0.004381 -0.035882 -0.023991  0.005215  0.030249   \n3HP  0.014603  0.054449  0.107646  0.133722  0.112652  0.082403  0.086993   \n0HP -0.083004 -0.195734  0.233419  0.103958 -0.181115  0.055553  0.173806   \n1HP -0.277602 -0.044345  0.117603 -0.145055 -0.111430  0.130923  0.032812   \n2HP -0.093238  0.187288  0.217663  0.070172  0.100385  0.156587 -0.011208   \n3HP  0.222699  0.093238 -0.146516  0.177217  0.248526 -0.071147 -0.121339   \n0HP  1.189431 -0.177866 -0.774816  0.501518  0.993697 -0.348017 -0.811363   \n1HP  0.171369  0.117765 -0.097055  0.009746  0.060913 -0.072690 -0.056040   \n2HP -0.402027  0.548219  0.931565 -0.218881 -1.079788  0.378068  1.610950   \n3HP -0.206293 -0.007310  0.222536 -0.005685  0.031675  0.242434 -0.002437   \n\n       7         8         9       ...    121255    121256    121257  \\\n0HP -0.058621 -0.046521 -0.049859  ...  0.027954 -0.024825 -0.088244   \n1HP -0.010684  0.029380  0.104576  ... -0.145256 -0.118753 -0.078689   \n2HP  0.007510 -0.016481 -0.041932  ... -0.002295  0.037134  0.042558   \n3HP  0.110566  0.127673  0.113487  ... -0.002921 -0.051737 -0.066757   \n0HP -0.046944 -0.111918  0.059614  ...  0.198333 -0.118578 -0.161136   \n1HP -0.197034 -0.074883  0.009584  ...  0.048568 -0.294332 -0.048081   \n2HP -0.132060 -0.127512 -0.157887  ... -0.019492 -0.051817  0.037198   \n3HP -0.013969  0.120202  0.071309  ... -0.195897 -0.017381  0.094537   \n0HP  0.424362  0.988012  0.089339  ... -0.386190 -0.520605  0.663141   \n1HP  0.099085  0.138476 -0.008934  ... -0.205887 -0.132385  0.548625   \n2HP -0.186800 -1.645874  0.019492  ...  0.906388  0.231876 -0.585985   \n3HP -0.164872  0.405276  0.704968  ... -0.008122 -0.116953  0.075532   \n\n       121258    121259    121260    121261    121262    121263    121264  \n0HP -0.135391 -0.147908 -0.109523 -0.025034  0.027954  0.083029  0.128090  \n1HP -0.005136  0.041502  0.033900  0.037393  0.057733  0.061431  0.034311  \n2HP  0.046104  0.044226  0.068634  0.076353  0.027746 -0.049233 -0.112652  \n3HP -0.038802  0.026077  0.090956  0.081986  0.024408 -0.030458 -0.024825  \n0HP -0.268505 -0.112568  0.324545  0.142456 -0.316424 -0.063675  0.267368  \n1HP  0.197196 -0.070172 -0.089014  0.206130  0.042883 -0.279551  0.036223  \n2HP  0.022903 -0.220749 -0.208892  0.125237  0.260871 -0.131735 -0.382372  \n3HP -0.137095 -0.186638  0.158049  0.037523 -0.207105 -0.215064 -0.439062  \n0HP  0.909231 -0.319185 -1.363643 -0.231470  0.944966 -0.082030 -1.362831  \n1HP  0.335835 -0.205887  0.055634  0.289947 -0.140506 -0.254617  0.198983  \n2HP -0.159999  0.561619  0.277358 -0.382941 -0.311875  0.139288  0.194110  \n3HP  0.172587  0.011777 -0.039797  0.080405  0.016650 -0.028020 -0.019898  \n\n[12 rows x 121265 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>121255</th>\n      <th>121256</th>\n      <th>121257</th>\n      <th>121258</th>\n      <th>121259</th>\n      <th>121260</th>\n      <th>121261</th>\n      <th>121262</th>\n      <th>121263</th>\n      <th>121264</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0HP</th>\n      <td>0.053197</td>\n      <td>0.088662</td>\n      <td>0.099718</td>\n      <td>0.058621</td>\n      <td>-0.004590</td>\n      <td>-0.056952</td>\n      <td>-0.071764</td>\n      <td>-0.058621</td>\n      <td>-0.046521</td>\n      <td>-0.049859</td>\n      <td>...</td>\n      <td>0.027954</td>\n      <td>-0.024825</td>\n      <td>-0.088244</td>\n      <td>-0.135391</td>\n      <td>-0.147908</td>\n      <td>-0.109523</td>\n      <td>-0.025034</td>\n      <td>0.027954</td>\n      <td>0.083029</td>\n      <td>0.128090</td>\n    </tr>\n    <tr>\n      <th>1HP</th>\n      <td>0.145667</td>\n      <td>0.097796</td>\n      <td>0.054856</td>\n      <td>0.036982</td>\n      <td>0.054445</td>\n      <td>0.021162</td>\n      <td>-0.003698</td>\n      <td>-0.010684</td>\n      <td>0.029380</td>\n      <td>0.104576</td>\n      <td>...</td>\n      <td>-0.145256</td>\n      <td>-0.118753</td>\n      <td>-0.078689</td>\n      <td>-0.005136</td>\n      <td>0.041502</td>\n      <td>0.033900</td>\n      <td>0.037393</td>\n      <td>0.057733</td>\n      <td>0.061431</td>\n      <td>0.034311</td>\n    </tr>\n    <tr>\n      <th>2HP</th>\n      <td>0.064254</td>\n      <td>0.063002</td>\n      <td>-0.004381</td>\n      <td>-0.035882</td>\n      <td>-0.023991</td>\n      <td>0.005215</td>\n      <td>0.030249</td>\n      <td>0.007510</td>\n      <td>-0.016481</td>\n      <td>-0.041932</td>\n      <td>...</td>\n      <td>-0.002295</td>\n      <td>0.037134</td>\n      <td>0.042558</td>\n      <td>0.046104</td>\n      <td>0.044226</td>\n      <td>0.068634</td>\n      <td>0.076353</td>\n      <td>0.027746</td>\n      <td>-0.049233</td>\n      <td>-0.112652</td>\n    </tr>\n    <tr>\n      <th>3HP</th>\n      <td>0.014603</td>\n      <td>0.054449</td>\n      <td>0.107646</td>\n      <td>0.133722</td>\n      <td>0.112652</td>\n      <td>0.082403</td>\n      <td>0.086993</td>\n      <td>0.110566</td>\n      <td>0.127673</td>\n      <td>0.113487</td>\n      <td>...</td>\n      <td>-0.002921</td>\n      <td>-0.051737</td>\n      <td>-0.066757</td>\n      <td>-0.038802</td>\n      <td>0.026077</td>\n      <td>0.090956</td>\n      <td>0.081986</td>\n      <td>0.024408</td>\n      <td>-0.030458</td>\n      <td>-0.024825</td>\n    </tr>\n    <tr>\n      <th>0HP</th>\n      <td>-0.083004</td>\n      <td>-0.195734</td>\n      <td>0.233419</td>\n      <td>0.103958</td>\n      <td>-0.181115</td>\n      <td>0.055553</td>\n      <td>0.173806</td>\n      <td>-0.046944</td>\n      <td>-0.111918</td>\n      <td>0.059614</td>\n      <td>...</td>\n      <td>0.198333</td>\n      <td>-0.118578</td>\n      <td>-0.161136</td>\n      <td>-0.268505</td>\n      <td>-0.112568</td>\n      <td>0.324545</td>\n      <td>0.142456</td>\n      <td>-0.316424</td>\n      <td>-0.063675</td>\n      <td>0.267368</td>\n    </tr>\n    <tr>\n      <th>1HP</th>\n      <td>-0.277602</td>\n      <td>-0.044345</td>\n      <td>0.117603</td>\n      <td>-0.145055</td>\n      <td>-0.111430</td>\n      <td>0.130923</td>\n      <td>0.032812</td>\n      <td>-0.197034</td>\n      <td>-0.074883</td>\n      <td>0.009584</td>\n      <td>...</td>\n      <td>0.048568</td>\n      <td>-0.294332</td>\n      <td>-0.048081</td>\n      <td>0.197196</td>\n      <td>-0.070172</td>\n      <td>-0.089014</td>\n      <td>0.206130</td>\n      <td>0.042883</td>\n      <td>-0.279551</td>\n      <td>0.036223</td>\n    </tr>\n    <tr>\n      <th>2HP</th>\n      <td>-0.093238</td>\n      <td>0.187288</td>\n      <td>0.217663</td>\n      <td>0.070172</td>\n      <td>0.100385</td>\n      <td>0.156587</td>\n      <td>-0.011208</td>\n      <td>-0.132060</td>\n      <td>-0.127512</td>\n      <td>-0.157887</td>\n      <td>...</td>\n      <td>-0.019492</td>\n      <td>-0.051817</td>\n      <td>0.037198</td>\n      <td>0.022903</td>\n      <td>-0.220749</td>\n      <td>-0.208892</td>\n      <td>0.125237</td>\n      <td>0.260871</td>\n      <td>-0.131735</td>\n      <td>-0.382372</td>\n    </tr>\n    <tr>\n      <th>3HP</th>\n      <td>0.222699</td>\n      <td>0.093238</td>\n      <td>-0.146516</td>\n      <td>0.177217</td>\n      <td>0.248526</td>\n      <td>-0.071147</td>\n      <td>-0.121339</td>\n      <td>-0.013969</td>\n      <td>0.120202</td>\n      <td>0.071309</td>\n      <td>...</td>\n      <td>-0.195897</td>\n      <td>-0.017381</td>\n      <td>0.094537</td>\n      <td>-0.137095</td>\n      <td>-0.186638</td>\n      <td>0.158049</td>\n      <td>0.037523</td>\n      <td>-0.207105</td>\n      <td>-0.215064</td>\n      <td>-0.439062</td>\n    </tr>\n    <tr>\n      <th>0HP</th>\n      <td>1.189431</td>\n      <td>-0.177866</td>\n      <td>-0.774816</td>\n      <td>0.501518</td>\n      <td>0.993697</td>\n      <td>-0.348017</td>\n      <td>-0.811363</td>\n      <td>0.424362</td>\n      <td>0.988012</td>\n      <td>0.089339</td>\n      <td>...</td>\n      <td>-0.386190</td>\n      <td>-0.520605</td>\n      <td>0.663141</td>\n      <td>0.909231</td>\n      <td>-0.319185</td>\n      <td>-1.363643</td>\n      <td>-0.231470</td>\n      <td>0.944966</td>\n      <td>-0.082030</td>\n      <td>-1.362831</td>\n    </tr>\n    <tr>\n      <th>1HP</th>\n      <td>0.171369</td>\n      <td>0.117765</td>\n      <td>-0.097055</td>\n      <td>0.009746</td>\n      <td>0.060913</td>\n      <td>-0.072690</td>\n      <td>-0.056040</td>\n      <td>0.099085</td>\n      <td>0.138476</td>\n      <td>-0.008934</td>\n      <td>...</td>\n      <td>-0.205887</td>\n      <td>-0.132385</td>\n      <td>0.548625</td>\n      <td>0.335835</td>\n      <td>-0.205887</td>\n      <td>0.055634</td>\n      <td>0.289947</td>\n      <td>-0.140506</td>\n      <td>-0.254617</td>\n      <td>0.198983</td>\n    </tr>\n    <tr>\n      <th>2HP</th>\n      <td>-0.402027</td>\n      <td>0.548219</td>\n      <td>0.931565</td>\n      <td>-0.218881</td>\n      <td>-1.079788</td>\n      <td>0.378068</td>\n      <td>1.610950</td>\n      <td>-0.186800</td>\n      <td>-1.645874</td>\n      <td>0.019492</td>\n      <td>...</td>\n      <td>0.906388</td>\n      <td>0.231876</td>\n      <td>-0.585985</td>\n      <td>-0.159999</td>\n      <td>0.561619</td>\n      <td>0.277358</td>\n      <td>-0.382941</td>\n      <td>-0.311875</td>\n      <td>0.139288</td>\n      <td>0.194110</td>\n    </tr>\n    <tr>\n      <th>3HP</th>\n      <td>-0.206293</td>\n      <td>-0.007310</td>\n      <td>0.222536</td>\n      <td>-0.005685</td>\n      <td>0.031675</td>\n      <td>0.242434</td>\n      <td>-0.002437</td>\n      <td>-0.164872</td>\n      <td>0.405276</td>\n      <td>0.704968</td>\n      <td>...</td>\n      <td>-0.008122</td>\n      <td>-0.116953</td>\n      <td>0.075532</td>\n      <td>0.172587</td>\n      <td>0.011777</td>\n      <td>-0.039797</td>\n      <td>0.080405</td>\n      <td>0.016650</td>\n      <td>-0.028020</td>\n      <td>-0.019898</td>\n    </tr>\n  </tbody>\n</table>\n<p>12 rows × 121265 columns</p>\n</div>"
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=df.iloc[:,:first_nan_index]\n",
    "data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now the NAN's are removed we can break the data into smaller 1000 chunks this way we can do a train test split with more than the 12 tests we have. This is possible because the data is relatively uniform over the course of time in each test\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "outputs": [],
   "source": [
    "normal = data.iloc[:4]\n",
    "fault = data.iloc[4:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "outputs": [],
   "source": [
    "def split_dataframe(df, chunk_size,fault):\n",
    "    \"\"\"\n",
    "    Split a pandas DataFrame into smaller DataFrames with a specified number of rows.\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The DataFrame to split.\n",
    "    chunk_size (int): The number of rows per smaller DataFrame. Default is 100.\n",
    "    Returns:\n",
    "    A list of smaller DataFrames.\n",
    "    \"\"\"\n",
    "    # divide the DataFrame into smaller chunks with chunk_size rows each\n",
    "    df = df.T\n",
    "    dfs = np.array_split(df, len(df) // chunk_size)\n",
    "    print(len(df))\n",
    "    for i in range(len(dfs)):\n",
    "        dfs[i] = dfs[i].reset_index(drop=True)\n",
    "    dfs = pd.concat(dfs, axis=1)\n",
    "\n",
    "    dfs = dfs.T\n",
    "    dfs.insert(0,'Fault',fault)\n",
    "\n",
    "    mask = dfs.isna()\n",
    "    first_nan_index = mask.any(axis=0).idxmax()\n",
    "    dfs=dfs.iloc[:,:first_nan_index]\n",
    "\n",
    "\n",
    "  # for i, chunk in enumerate(df_chunks):\n",
    "  #       prefix = f\"{i}\"\n",
    "  #       new_column_names = {old_col: prefix + str(i) + \"_\" + old_col for old_col in chunk.columns}\n",
    "  #       chunk = chunk.rename(columns=new_column_names)\n",
    "  #       df_chunks[i] = chunk\n",
    "\n",
    "    return dfs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7133\n",
      "7133\n"
     ]
    }
   ],
   "source": [
    "normal = split_dataframe(normal,2000,0)\n",
    "fault = split_dataframe(fault,2000,1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "outputs": [
    {
     "data": {
      "text/plain": "     Fault         0         1         2         3         4         5  \\\n0HP      0  0.000000  0.053197  0.088662  0.099718  0.058621 -0.004590   \n1HP      0  0.000000  0.145667  0.097796  0.054856  0.036982  0.054445   \n2HP      0  0.000000  0.064254  0.063002 -0.004381 -0.035882 -0.023991   \n3HP      0  0.000000  0.014603  0.054449  0.107646  0.133722  0.112652   \n0HP      0  0.029623 -0.005841 -0.044644 -0.044018 -0.038385 -0.017524   \n..     ...       ...       ...       ...       ...       ...       ...   \n3HP      1 -0.082355 -0.015919  0.431265  0.335916 -0.166658 -0.339489   \n0HP      1 -1.177655 -1.128112  0.617660  0.704968 -0.986387 -1.535824   \n1HP      1 -0.061319  0.700501  0.507610 -0.489742 -0.342738  0.834510   \n2HP      1 -0.192080  0.376850 -0.088527 -0.354109  0.283043  0.399997   \n3HP      1  0.124669  0.204262  0.166902 -0.264363 -0.176242  0.415834   \n\n            6         7         8  ...      2366      2367      2368  \\\n0HP -0.056952 -0.071764 -0.058621  ...  0.155836  0.136017  0.096172   \n1HP  0.021162 -0.003698 -0.010684  ... -0.029996  0.025887  0.068827   \n2HP  0.005215  0.030249  0.007510  ...  0.063002  0.027329  0.015020   \n3HP  0.082403  0.086993  0.110566  ... -0.005215  0.073224  0.082612   \n0HP -0.004172 -0.000626  0.002295  ...  0.007510 -0.007719  0.004381   \n..        ...       ...       ...  ...       ...       ...       ...   \n3HP -0.106882  0.094862  0.202719  ...  0.038497 -0.137420 -0.195897   \n0HP  0.155938  1.055828 -0.402433  ...  0.556340  0.795526 -0.386190   \n1HP  0.769943 -0.488118 -0.261927  ...  0.325276  0.478371 -0.205887   \n2HP -0.267206 -0.310251  0.068223  ... -0.758978  0.106801  0.906388   \n3HP  0.055228 -0.713496 -0.147816  ... -0.028020  0.205480 -0.008122   \n\n         2369      2370      2371      2372      2373      2374      2375  \n0HP  0.074684  0.059664  0.076770  0.073433  0.062585  0.046104  0.024199  \n1HP  0.099851  0.080949  0.054240  0.031435  0.026709  0.048076  0.006369  \n2HP  0.018150  0.022948  0.002503 -0.044644 -0.075102 -0.062793 -0.010222  \n3HP  0.042975 -0.010431 -0.017941  0.012308  0.021279  0.012308 -0.055283  \n0HP  0.004381  0.010014  0.042349  0.086158  0.135391  0.151038  0.112026  \n..        ...       ...       ...       ...       ...       ...       ...  \n3HP -0.017381  0.094537 -0.137095 -0.186638  0.158049  0.037523 -0.207105  \n0HP -0.520605  0.663141  0.909231 -0.319185 -1.363643 -0.231470  0.944966  \n1HP -0.132385  0.548625  0.335835 -0.205887  0.055634  0.289947 -0.140506  \n2HP  0.231876 -0.585985 -0.159999  0.561619  0.277358 -0.382941 -0.311875  \n3HP -0.116953  0.075532  0.172587  0.011777 -0.039797  0.080405  0.016650  \n\n[612 rows x 2377 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Fault</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>...</th>\n      <th>2366</th>\n      <th>2367</th>\n      <th>2368</th>\n      <th>2369</th>\n      <th>2370</th>\n      <th>2371</th>\n      <th>2372</th>\n      <th>2373</th>\n      <th>2374</th>\n      <th>2375</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0HP</th>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.053197</td>\n      <td>0.088662</td>\n      <td>0.099718</td>\n      <td>0.058621</td>\n      <td>-0.004590</td>\n      <td>-0.056952</td>\n      <td>-0.071764</td>\n      <td>-0.058621</td>\n      <td>...</td>\n      <td>0.155836</td>\n      <td>0.136017</td>\n      <td>0.096172</td>\n      <td>0.074684</td>\n      <td>0.059664</td>\n      <td>0.076770</td>\n      <td>0.073433</td>\n      <td>0.062585</td>\n      <td>0.046104</td>\n      <td>0.024199</td>\n    </tr>\n    <tr>\n      <th>1HP</th>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.145667</td>\n      <td>0.097796</td>\n      <td>0.054856</td>\n      <td>0.036982</td>\n      <td>0.054445</td>\n      <td>0.021162</td>\n      <td>-0.003698</td>\n      <td>-0.010684</td>\n      <td>...</td>\n      <td>-0.029996</td>\n      <td>0.025887</td>\n      <td>0.068827</td>\n      <td>0.099851</td>\n      <td>0.080949</td>\n      <td>0.054240</td>\n      <td>0.031435</td>\n      <td>0.026709</td>\n      <td>0.048076</td>\n      <td>0.006369</td>\n    </tr>\n    <tr>\n      <th>2HP</th>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.064254</td>\n      <td>0.063002</td>\n      <td>-0.004381</td>\n      <td>-0.035882</td>\n      <td>-0.023991</td>\n      <td>0.005215</td>\n      <td>0.030249</td>\n      <td>0.007510</td>\n      <td>...</td>\n      <td>0.063002</td>\n      <td>0.027329</td>\n      <td>0.015020</td>\n      <td>0.018150</td>\n      <td>0.022948</td>\n      <td>0.002503</td>\n      <td>-0.044644</td>\n      <td>-0.075102</td>\n      <td>-0.062793</td>\n      <td>-0.010222</td>\n    </tr>\n    <tr>\n      <th>3HP</th>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.014603</td>\n      <td>0.054449</td>\n      <td>0.107646</td>\n      <td>0.133722</td>\n      <td>0.112652</td>\n      <td>0.082403</td>\n      <td>0.086993</td>\n      <td>0.110566</td>\n      <td>...</td>\n      <td>-0.005215</td>\n      <td>0.073224</td>\n      <td>0.082612</td>\n      <td>0.042975</td>\n      <td>-0.010431</td>\n      <td>-0.017941</td>\n      <td>0.012308</td>\n      <td>0.021279</td>\n      <td>0.012308</td>\n      <td>-0.055283</td>\n    </tr>\n    <tr>\n      <th>0HP</th>\n      <td>0</td>\n      <td>0.029623</td>\n      <td>-0.005841</td>\n      <td>-0.044644</td>\n      <td>-0.044018</td>\n      <td>-0.038385</td>\n      <td>-0.017524</td>\n      <td>-0.004172</td>\n      <td>-0.000626</td>\n      <td>0.002295</td>\n      <td>...</td>\n      <td>0.007510</td>\n      <td>-0.007719</td>\n      <td>0.004381</td>\n      <td>0.004381</td>\n      <td>0.010014</td>\n      <td>0.042349</td>\n      <td>0.086158</td>\n      <td>0.135391</td>\n      <td>0.151038</td>\n      <td>0.112026</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3HP</th>\n      <td>1</td>\n      <td>-0.082355</td>\n      <td>-0.015919</td>\n      <td>0.431265</td>\n      <td>0.335916</td>\n      <td>-0.166658</td>\n      <td>-0.339489</td>\n      <td>-0.106882</td>\n      <td>0.094862</td>\n      <td>0.202719</td>\n      <td>...</td>\n      <td>0.038497</td>\n      <td>-0.137420</td>\n      <td>-0.195897</td>\n      <td>-0.017381</td>\n      <td>0.094537</td>\n      <td>-0.137095</td>\n      <td>-0.186638</td>\n      <td>0.158049</td>\n      <td>0.037523</td>\n      <td>-0.207105</td>\n    </tr>\n    <tr>\n      <th>0HP</th>\n      <td>1</td>\n      <td>-1.177655</td>\n      <td>-1.128112</td>\n      <td>0.617660</td>\n      <td>0.704968</td>\n      <td>-0.986387</td>\n      <td>-1.535824</td>\n      <td>0.155938</td>\n      <td>1.055828</td>\n      <td>-0.402433</td>\n      <td>...</td>\n      <td>0.556340</td>\n      <td>0.795526</td>\n      <td>-0.386190</td>\n      <td>-0.520605</td>\n      <td>0.663141</td>\n      <td>0.909231</td>\n      <td>-0.319185</td>\n      <td>-1.363643</td>\n      <td>-0.231470</td>\n      <td>0.944966</td>\n    </tr>\n    <tr>\n      <th>1HP</th>\n      <td>1</td>\n      <td>-0.061319</td>\n      <td>0.700501</td>\n      <td>0.507610</td>\n      <td>-0.489742</td>\n      <td>-0.342738</td>\n      <td>0.834510</td>\n      <td>0.769943</td>\n      <td>-0.488118</td>\n      <td>-0.261927</td>\n      <td>...</td>\n      <td>0.325276</td>\n      <td>0.478371</td>\n      <td>-0.205887</td>\n      <td>-0.132385</td>\n      <td>0.548625</td>\n      <td>0.335835</td>\n      <td>-0.205887</td>\n      <td>0.055634</td>\n      <td>0.289947</td>\n      <td>-0.140506</td>\n    </tr>\n    <tr>\n      <th>2HP</th>\n      <td>1</td>\n      <td>-0.192080</td>\n      <td>0.376850</td>\n      <td>-0.088527</td>\n      <td>-0.354109</td>\n      <td>0.283043</td>\n      <td>0.399997</td>\n      <td>-0.267206</td>\n      <td>-0.310251</td>\n      <td>0.068223</td>\n      <td>...</td>\n      <td>-0.758978</td>\n      <td>0.106801</td>\n      <td>0.906388</td>\n      <td>0.231876</td>\n      <td>-0.585985</td>\n      <td>-0.159999</td>\n      <td>0.561619</td>\n      <td>0.277358</td>\n      <td>-0.382941</td>\n      <td>-0.311875</td>\n    </tr>\n    <tr>\n      <th>3HP</th>\n      <td>1</td>\n      <td>0.124669</td>\n      <td>0.204262</td>\n      <td>0.166902</td>\n      <td>-0.264363</td>\n      <td>-0.176242</td>\n      <td>0.415834</td>\n      <td>0.055228</td>\n      <td>-0.713496</td>\n      <td>-0.147816</td>\n      <td>...</td>\n      <td>-0.028020</td>\n      <td>0.205480</td>\n      <td>-0.008122</td>\n      <td>-0.116953</td>\n      <td>0.075532</td>\n      <td>0.172587</td>\n      <td>0.011777</td>\n      <td>-0.039797</td>\n      <td>0.080405</td>\n      <td>0.016650</td>\n    </tr>\n  </tbody>\n</table>\n<p>612 rows × 2377 columns</p>\n</div>"
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.concat([normal,fault],axis=0)\n",
    "data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "outputs": [],
   "source": [
    "X = data[data.columns[1:]].values\n",
    "y = data[data.columns[0]].values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "outputs": [
    {
     "data": {
      "text/plain": "((612, 2376), (612,))"
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,y.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "outputs": [
    {
     "data": {
      "text/plain": "244"
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "len(X_train)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "outputs": [],
   "source": [
    " def reshaper(X_train,X_test=0):\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1], 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1], 1)\n",
    "    input_shape = (1, X_train.shape[2], 1)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    X_train /= np.max(X_train)\n",
    "    X_test /= np.max(X_train)\n",
    "    return X_train, X_test, input_shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "outputs": [],
   "source": [
    "X_train,X_validation,input_shape = reshaper(X_train,X_validation)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, kernel_size=(1, 5), strides=(1, 1), activation='relu', input_shape=input_shape))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(1, 2), strides=(1, 2)))\n",
    "model.add(keras.layers.Conv2D(64, kernel_size=(1, 5), strides=(1, 1), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(1, 2), strides=(1, 2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(1, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/hhamie/miniconda3/envs/tfwsl/lib/python3.10/site-packages/keras/engine/training.py\", line 1727, in test_function  *\n        return step_function(self, iterator)\n    File \"/home/hhamie/miniconda3/envs/tfwsl/lib/python3.10/site-packages/keras/engine/training.py\", line 1713, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/hhamie/miniconda3/envs/tfwsl/lib/python3.10/site-packages/keras/engine/training.py\", line 1701, in run_step  **\n        outputs = model.test_step(data)\n    File \"/home/hhamie/miniconda3/envs/tfwsl/lib/python3.10/site-packages/keras/engine/training.py\", line 1665, in test_step\n        y_pred = self(x, training=False)\n    File \"/home/hhamie/miniconda3/envs/tfwsl/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/hhamie/miniconda3/envs/tfwsl/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 1, 3030, 1), found shape=(None, 3030)\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[260], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/tfwsl/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m/tmp/__autograph_generated_fileoql0gfo7.py:15\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__test_function\u001B[0;34m(iterator)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     14\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m---> 15\u001B[0m     retval_ \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(step_function), (ag__\u001B[38;5;241m.\u001B[39mld(\u001B[38;5;28mself\u001B[39m), ag__\u001B[38;5;241m.\u001B[39mld(iterator)), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[1;32m     17\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "\u001B[0;31mValueError\u001B[0m: in user code:\n\n    File \"/home/hhamie/miniconda3/envs/tfwsl/lib/python3.10/site-packages/keras/engine/training.py\", line 1727, in test_function  *\n        return step_function(self, iterator)\n    File \"/home/hhamie/miniconda3/envs/tfwsl/lib/python3.10/site-packages/keras/engine/training.py\", line 1713, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/hhamie/miniconda3/envs/tfwsl/lib/python3.10/site-packages/keras/engine/training.py\", line 1701, in run_step  **\n        outputs = model.test_step(data)\n    File \"/home/hhamie/miniconda3/envs/tfwsl/lib/python3.10/site-packages/keras/engine/training.py\", line 1665, in test_step\n        y_pred = self(x, training=False)\n    File \"/home/hhamie/miniconda3/envs/tfwsl/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/hhamie/miniconda3/envs/tfwsl/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 1, 3030, 1), found shape=(None, 3030)\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "4/4 [==============================] - 1s 43ms/step - loss: 0.3012 - accuracy: 0.9877 - val_loss: 2.8082e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0751 - accuracy: 0.9877 - val_loss: 2.5131e-07 - val_accuracy: 1.0000\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1090 - accuracy: 0.9877 - val_loss: 3.2544e-07 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0753 - accuracy: 0.9877 - val_loss: 2.5918e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0650 - accuracy: 0.9877 - val_loss: 4.6462e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0645 - accuracy: 0.9877 - val_loss: 2.7450e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0576 - accuracy: 0.9877 - val_loss: 5.8466e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0613 - accuracy: 0.9877 - val_loss: 6.9680e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0510 - accuracy: 0.9877 - val_loss: 1.2293e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0513 - accuracy: 0.9877 - val_loss: 3.2909e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0566 - accuracy: 0.9877 - val_loss: 4.5280e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0495 - accuracy: 0.9877 - val_loss: 2.5811e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0473 - accuracy: 0.9877 - val_loss: 1.2360e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0524 - accuracy: 0.9877 - val_loss: 1.4401e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0574 - accuracy: 0.9877 - val_loss: 3.7392e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0549 - accuracy: 0.9877 - val_loss: 4.7096e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0509 - accuracy: 0.9877 - val_loss: 8.0834e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0541 - accuracy: 0.9877 - val_loss: 5.7597e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0464 - accuracy: 0.9877 - val_loss: 4.0794e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0441 - accuracy: 0.9877 - val_loss: 2.3568e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0491 - accuracy: 0.9877 - val_loss: 3.0187e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0377 - accuracy: 0.9877 - val_loss: 3.5829e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0487 - accuracy: 0.9877 - val_loss: 5.8927e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0471 - accuracy: 0.9877 - val_loss: 4.5740e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0403 - accuracy: 0.9877 - val_loss: 3.7727e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0389 - accuracy: 0.9877 - val_loss: 2.6626e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0445 - accuracy: 0.9877 - val_loss: 2.5037e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0416 - accuracy: 0.9877 - val_loss: 8.5112e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0383 - accuracy: 0.9877 - val_loss: 4.9754e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0339 - accuracy: 0.9877 - val_loss: 2.9510e-04 - val_accuracy: 1.0000\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0360 - accuracy: 0.9877 - val_loss: 1.5486e-04 - val_accuracy: 1.0000\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0346 - accuracy: 0.9877 - val_loss: 5.4459e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0317 - accuracy: 0.9877 - val_loss: 2.2699e-04 - val_accuracy: 1.0000\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0262 - accuracy: 0.9877 - val_loss: 9.3668e-05 - val_accuracy: 1.0000\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0229 - accuracy: 0.9877 - val_loss: 1.2428e-04 - val_accuracy: 1.0000\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0202 - accuracy: 0.9877 - val_loss: 7.0072e-05 - val_accuracy: 1.0000\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0185 - accuracy: 0.9877 - val_loss: 3.2954e-05 - val_accuracy: 1.0000\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0155 - accuracy: 0.9877 - val_loss: 2.6565e-05 - val_accuracy: 1.0000\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0144 - accuracy: 0.9877 - val_loss: 2.7039e-05 - val_accuracy: 1.0000\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0132 - accuracy: 0.9877 - val_loss: 2.5123e-05 - val_accuracy: 1.0000\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0129 - accuracy: 0.9877 - val_loss: 1.5160e-05 - val_accuracy: 1.0000\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0138 - accuracy: 0.9877 - val_loss: 9.0861e-06 - val_accuracy: 1.0000\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0110 - accuracy: 0.9877 - val_loss: 1.7830e-05 - val_accuracy: 1.0000\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0112 - accuracy: 0.9877 - val_loss: 1.1700e-05 - val_accuracy: 1.0000\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0102 - accuracy: 0.9877 - val_loss: 3.8225e-06 - val_accuracy: 1.0000\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0105 - accuracy: 0.9877 - val_loss: 2.1829e-06 - val_accuracy: 1.0000\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0100 - accuracy: 0.9877 - val_loss: 3.4974e-06 - val_accuracy: 1.0000\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0100 - accuracy: 0.9877 - val_loss: 3.8954e-06 - val_accuracy: 1.0000\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0099 - accuracy: 0.9877 - val_loss: 2.0143e-06 - val_accuracy: 1.0000\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0092 - accuracy: 0.9877 - val_loss: 1.2066e-06 - val_accuracy: 1.0000\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0096 - accuracy: 0.9877 - val_loss: 8.1746e-07 - val_accuracy: 1.0000\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0092 - accuracy: 0.9877 - val_loss: 8.1565e-07 - val_accuracy: 1.0000\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0093 - accuracy: 0.9877 - val_loss: 9.3161e-07 - val_accuracy: 1.0000\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0090 - accuracy: 0.9877 - val_loss: 1.0452e-06 - val_accuracy: 1.0000\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0091 - accuracy: 0.9877 - val_loss: 7.4118e-07 - val_accuracy: 1.0000\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0090 - accuracy: 0.9877 - val_loss: 4.7517e-07 - val_accuracy: 1.0000\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0089 - accuracy: 0.9877 - val_loss: 3.2816e-07 - val_accuracy: 1.0000\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0090 - accuracy: 0.9877 - val_loss: 3.1511e-07 - val_accuracy: 1.0000\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0088 - accuracy: 0.9877 - val_loss: 3.1443e-07 - val_accuracy: 1.0000\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0087 - accuracy: 0.9877 - val_loss: 2.8860e-07 - val_accuracy: 1.0000\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0088 - accuracy: 0.9877 - val_loss: 2.4473e-07 - val_accuracy: 1.0000\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0087 - accuracy: 0.9877 - val_loss: 2.0963e-07 - val_accuracy: 1.0000\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0087 - accuracy: 0.9877 - val_loss: 2.0764e-07 - val_accuracy: 1.0000\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0088 - accuracy: 0.9877 - val_loss: 2.0937e-07 - val_accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0088 - accuracy: 0.9877 - val_loss: 1.7959e-07 - val_accuracy: 1.0000\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0086 - accuracy: 0.9877 - val_loss: 1.6186e-07 - val_accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0087 - accuracy: 0.9877 - val_loss: 1.8384e-07 - val_accuracy: 1.0000\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0086 - accuracy: 0.9877 - val_loss: 1.8867e-07 - val_accuracy: 1.0000\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0090 - accuracy: 0.9877 - val_loss: 1.7095e-07 - val_accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0087 - accuracy: 0.9877 - val_loss: 2.0805e-07 - val_accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0086 - accuracy: 0.9877 - val_loss: 1.9285e-07 - val_accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0086 - accuracy: 0.9877 - val_loss: 1.5935e-07 - val_accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0087 - accuracy: 0.9877 - val_loss: 1.3760e-07 - val_accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0086 - accuracy: 0.9877 - val_loss: 1.2011e-07 - val_accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0086 - accuracy: 0.9877 - val_loss: 1.5312e-07 - val_accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0088 - accuracy: 0.9877 - val_loss: 1.7435e-07 - val_accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0087 - accuracy: 0.9877 - val_loss: 1.7460e-07 - val_accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0086 - accuracy: 0.9877 - val_loss: 1.4433e-07 - val_accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0087 - accuracy: 0.9877 - val_loss: 1.3002e-07 - val_accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0086 - accuracy: 0.9877 - val_loss: 1.0937e-07 - val_accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0086 - accuracy: 0.9877 - val_loss: 9.1925e-08 - val_accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0086 - accuracy: 0.9877 - val_loss: 9.5941e-08 - val_accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0085 - accuracy: 0.9877 - val_loss: 1.3592e-07 - val_accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0085 - accuracy: 0.9877 - val_loss: 1.4263e-07 - val_accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0085 - accuracy: 0.9877 - val_loss: 1.2311e-07 - val_accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0085 - accuracy: 0.9877 - val_loss: 1.0071e-07 - val_accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0085 - accuracy: 0.9877 - val_loss: 9.2050e-08 - val_accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0085 - accuracy: 0.9877 - val_loss: 7.3807e-08 - val_accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0084 - accuracy: 0.9877 - val_loss: 5.6573e-08 - val_accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0085 - accuracy: 0.9877 - val_loss: 4.0639e-08 - val_accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0084 - accuracy: 0.9877 - val_loss: 3.2452e-08 - val_accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0085 - accuracy: 0.9877 - val_loss: 3.7935e-08 - val_accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0085 - accuracy: 0.9877 - val_loss: 4.4169e-08 - val_accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0084 - accuracy: 0.9877 - val_loss: 4.6658e-08 - val_accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0084 - accuracy: 0.9877 - val_loss: 4.6358e-08 - val_accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0084 - accuracy: 0.9877 - val_loss: 3.9632e-08 - val_accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0084 - accuracy: 0.9877 - val_loss: 4.2279e-08 - val_accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0085 - accuracy: 0.9877 - val_loss: 3.5325e-08 - val_accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.9877 - val_loss: 3.0233e-08 - val_accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0084 - accuracy: 0.9877 - val_loss: 2.6457e-08 - val_accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0085 - accuracy: 0.9877 - val_loss: 3.2645e-08 - val_accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0084 - accuracy: 0.9877 - val_loss: 4.1402e-08 - val_accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0084 - accuracy: 0.9877 - val_loss: 4.1409e-08 - val_accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0084 - accuracy: 0.9877 - val_loss: 3.9092e-08 - val_accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0084 - accuracy: 0.9877 - val_loss: 3.9081e-08 - val_accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0083 - accuracy: 0.9877 - val_loss: 3.4343e-08 - val_accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0084 - accuracy: 0.9877 - val_loss: 3.5031e-08 - val_accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0084 - accuracy: 0.9877 - val_loss: 4.2083e-08 - val_accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0084 - accuracy: 0.9877 - val_loss: 4.0695e-08 - val_accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0084 - accuracy: 0.9877 - val_loss: 3.3785e-08 - val_accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0083 - accuracy: 0.9877 - val_loss: 2.8465e-08 - val_accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0083 - accuracy: 0.9877 - val_loss: 3.0845e-08 - val_accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0083 - accuracy: 0.9877 - val_loss: 4.8807e-08 - val_accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0083 - accuracy: 0.9877 - val_loss: 5.6344e-08 - val_accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0083 - accuracy: 0.9877 - val_loss: 5.2224e-08 - val_accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0083 - accuracy: 0.9877 - val_loss: 4.4125e-08 - val_accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.9877 - val_loss: 3.8196e-08 - val_accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0083 - accuracy: 0.9877 - val_loss: 3.0576e-08 - val_accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.9877 - val_loss: 2.6540e-08 - val_accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0083 - accuracy: 0.9877 - val_loss: 2.1051e-08 - val_accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0083 - accuracy: 0.9877 - val_loss: 2.1734e-08 - val_accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0083 - accuracy: 0.9877 - val_loss: 2.8730e-08 - val_accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0082 - accuracy: 0.9877 - val_loss: 3.2669e-08 - val_accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0082 - accuracy: 0.9877 - val_loss: 3.3002e-08 - val_accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0083 - accuracy: 0.9877 - val_loss: 2.8617e-08 - val_accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0082 - accuracy: 0.9877 - val_loss: 2.3347e-08 - val_accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0082 - accuracy: 0.9877 - val_loss: 2.1965e-08 - val_accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0082 - accuracy: 0.9877 - val_loss: 1.9995e-08 - val_accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.9877 - val_loss: 1.9195e-08 - val_accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0082 - accuracy: 0.9877 - val_loss: 1.8350e-08 - val_accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0082 - accuracy: 0.9877 - val_loss: 2.1165e-08 - val_accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0082 - accuracy: 0.9877 - val_loss: 2.6531e-08 - val_accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0082 - accuracy: 0.9877 - val_loss: 2.5298e-08 - val_accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0082 - accuracy: 0.9877 - val_loss: 2.2252e-08 - val_accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.9877 - val_loss: 2.1527e-08 - val_accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.9877 - val_loss: 1.8611e-08 - val_accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0082 - accuracy: 0.9877 - val_loss: 1.4803e-08 - val_accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0082 - accuracy: 0.9877 - val_loss: 1.5788e-08 - val_accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0082 - accuracy: 0.9877 - val_loss: 2.3946e-08 - val_accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0081 - accuracy: 0.9877 - val_loss: 2.7680e-08 - val_accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0082 - accuracy: 0.9877 - val_loss: 2.5352e-08 - val_accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.9877 - val_loss: 2.2614e-08 - val_accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0081 - accuracy: 0.9877 - val_loss: 1.6828e-08 - val_accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0081 - accuracy: 0.9877 - val_loss: 1.5381e-08 - val_accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0081 - accuracy: 0.9877 - val_loss: 1.5238e-08 - val_accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0081 - accuracy: 0.9877 - val_loss: 1.8223e-08 - val_accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.9877 - val_loss: 1.8286e-08 - val_accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0081 - accuracy: 0.9877 - val_loss: 1.9605e-08 - val_accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0081 - accuracy: 0.9877 - val_loss: 1.8412e-08 - val_accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0080 - accuracy: 0.9877 - val_loss: 1.5756e-08 - val_accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0081 - accuracy: 0.9877 - val_loss: 1.5653e-08 - val_accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0080 - accuracy: 0.9877 - val_loss: 1.5201e-08 - val_accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0080 - accuracy: 0.9877 - val_loss: 1.6802e-08 - val_accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0080 - accuracy: 0.9877 - val_loss: 1.8752e-08 - val_accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0080 - accuracy: 0.9877 - val_loss: 1.8461e-08 - val_accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0080 - accuracy: 0.9877 - val_loss: 1.6423e-08 - val_accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0080 - accuracy: 0.9877 - val_loss: 1.3655e-08 - val_accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0080 - accuracy: 0.9877 - val_loss: 1.4899e-08 - val_accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0080 - accuracy: 0.9877 - val_loss: 1.8049e-08 - val_accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0080 - accuracy: 0.9877 - val_loss: 2.9210e-08 - val_accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0080 - accuracy: 0.9877 - val_loss: 3.7840e-08 - val_accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0080 - accuracy: 0.9877 - val_loss: 3.7556e-08 - val_accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0080 - accuracy: 0.9877 - val_loss: 3.2199e-08 - val_accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0080 - accuracy: 0.9877 - val_loss: 2.5425e-08 - val_accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0079 - accuracy: 0.9877 - val_loss: 1.9444e-08 - val_accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0080 - accuracy: 0.9877 - val_loss: 1.6974e-08 - val_accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0079 - accuracy: 0.9877 - val_loss: 2.1542e-08 - val_accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0079 - accuracy: 0.9877 - val_loss: 2.3060e-08 - val_accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0079 - accuracy: 0.9877 - val_loss: 2.1972e-08 - val_accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0079 - accuracy: 0.9877 - val_loss: 1.9538e-08 - val_accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0079 - accuracy: 0.9877 - val_loss: 1.6161e-08 - val_accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0079 - accuracy: 0.9877 - val_loss: 1.7294e-08 - val_accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0079 - accuracy: 0.9877 - val_loss: 2.3165e-08 - val_accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0079 - accuracy: 0.9877 - val_loss: 2.8748e-08 - val_accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0079 - accuracy: 0.9877 - val_loss: 2.8847e-08 - val_accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0079 - accuracy: 0.9877 - val_loss: 2.3912e-08 - val_accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0079 - accuracy: 0.9877 - val_loss: 1.8792e-08 - val_accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0079 - accuracy: 0.9877 - val_loss: 1.4242e-08 - val_accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0079 - accuracy: 0.9877 - val_loss: 1.2785e-08 - val_accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0078 - accuracy: 0.9877 - val_loss: 1.2649e-08 - val_accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0078 - accuracy: 0.9877 - val_loss: 1.2972e-08 - val_accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0078 - accuracy: 0.9877 - val_loss: 1.4494e-08 - val_accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0078 - accuracy: 0.9877 - val_loss: 1.4404e-08 - val_accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0078 - accuracy: 0.9877 - val_loss: 1.3121e-08 - val_accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0078 - accuracy: 0.9877 - val_loss: 1.1446e-08 - val_accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0078 - accuracy: 0.9877 - val_loss: 1.0725e-08 - val_accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0078 - accuracy: 0.9877 - val_loss: 9.8713e-09 - val_accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0078 - accuracy: 0.9877 - val_loss: 8.4761e-09 - val_accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0078 - accuracy: 0.9877 - val_loss: 9.3944e-09 - val_accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0078 - accuracy: 0.9877 - val_loss: 1.2952e-08 - val_accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0077 - accuracy: 0.9877 - val_loss: 1.6066e-08 - val_accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0077 - accuracy: 0.9877 - val_loss: 1.6964e-08 - val_accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0077 - accuracy: 0.9877 - val_loss: 1.6143e-08 - val_accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0078 - accuracy: 0.9877 - val_loss: 1.3930e-08 - val_accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0077 - accuracy: 0.9877 - val_loss: 1.2351e-08 - val_accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0077 - accuracy: 0.9877 - val_loss: 1.2224e-08 - val_accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0077 - accuracy: 0.9877 - val_loss: 1.0943e-08 - val_accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0077 - accuracy: 0.9877 - val_loss: 1.1815e-08 - val_accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0077 - accuracy: 0.9877 - val_loss: 1.5430e-08 - val_accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0077 - accuracy: 0.9877 - val_loss: 1.7197e-08 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=200, batch_size=64, validation_data=(X_validation, y_validation))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.7197050894424137e-08\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_validation, y_validation, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Running model with 70 30 split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306\n",
      "306\n"
     ]
    },
    {
     "data": {
      "text/plain": "92"
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "print(len(X_train))\n",
    "print(len(X_train))\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n",
    "len(X_validation)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "outputs": [],
   "source": [
    "X_train,X_validation,input_shape = reshaper(X_train,X_validation)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0058 - accuracy: 0.9907 - val_loss: 0.0068 - val_accuracy: 0.9891\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0058 - accuracy: 0.9907 - val_loss: 0.0068 - val_accuracy: 0.9891\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0059 - accuracy: 0.9907 - val_loss: 0.0068 - val_accuracy: 0.9891\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0058 - accuracy: 0.9907 - val_loss: 0.0068 - val_accuracy: 0.9891\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0058 - accuracy: 0.9907 - val_loss: 0.0067 - val_accuracy: 0.9891\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0058 - accuracy: 0.9907 - val_loss: 0.0067 - val_accuracy: 0.9891\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0058 - accuracy: 0.9907 - val_loss: 0.0067 - val_accuracy: 0.9891\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0058 - accuracy: 0.9907 - val_loss: 0.0067 - val_accuracy: 0.9891\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0058 - accuracy: 0.9907 - val_loss: 0.0067 - val_accuracy: 0.9891\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0058 - accuracy: 0.9907 - val_loss: 0.0067 - val_accuracy: 0.9891\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0058 - accuracy: 0.9907 - val_loss: 0.0067 - val_accuracy: 0.9891\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0058 - accuracy: 0.9907 - val_loss: 0.0067 - val_accuracy: 0.9891\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0058 - accuracy: 0.9907 - val_loss: 0.0067 - val_accuracy: 0.9891\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0058 - accuracy: 0.9907 - val_loss: 0.0067 - val_accuracy: 0.9891\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0058 - accuracy: 0.9907 - val_loss: 0.0067 - val_accuracy: 0.9891\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0058 - accuracy: 0.9907 - val_loss: 0.0067 - val_accuracy: 0.9891\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0058 - accuracy: 0.9907 - val_loss: 0.0067 - val_accuracy: 0.9891\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0058 - accuracy: 0.9907 - val_loss: 0.0067 - val_accuracy: 0.9891\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0058 - accuracy: 0.9907 - val_loss: 0.0067 - val_accuracy: 0.9891\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0058 - accuracy: 0.9907 - val_loss: 0.0067 - val_accuracy: 0.9891\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0058 - accuracy: 0.9907 - val_loss: 0.0067 - val_accuracy: 0.9891\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0057 - accuracy: 0.9907 - val_loss: 0.0067 - val_accuracy: 0.9891\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0058 - accuracy: 0.9907 - val_loss: 0.0067 - val_accuracy: 0.9891\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0057 - accuracy: 0.9907 - val_loss: 0.0066 - val_accuracy: 0.9891\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0057 - accuracy: 0.9907 - val_loss: 0.0066 - val_accuracy: 0.9891\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0057 - accuracy: 0.9907 - val_loss: 0.0066 - val_accuracy: 0.9891\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0057 - accuracy: 0.9907 - val_loss: 0.0066 - val_accuracy: 0.9891\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0057 - accuracy: 0.9907 - val_loss: 0.0066 - val_accuracy: 0.9891\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0057 - accuracy: 0.9907 - val_loss: 0.0066 - val_accuracy: 0.9891\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0057 - accuracy: 0.9907 - val_loss: 0.0066 - val_accuracy: 0.9891\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0057 - accuracy: 0.9907 - val_loss: 0.0066 - val_accuracy: 0.9891\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0057 - accuracy: 0.9907 - val_loss: 0.0066 - val_accuracy: 0.9891\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0057 - accuracy: 0.9907 - val_loss: 0.0066 - val_accuracy: 0.9891\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0058 - accuracy: 0.9907 - val_loss: 0.0066 - val_accuracy: 0.9891\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0057 - accuracy: 0.9907 - val_loss: 0.0067 - val_accuracy: 0.9891\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0057 - accuracy: 0.9907 - val_loss: 0.0067 - val_accuracy: 0.9891\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0057 - accuracy: 0.9907 - val_loss: 0.0067 - val_accuracy: 0.9891\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0057 - accuracy: 0.9907 - val_loss: 0.0067 - val_accuracy: 0.9891\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0057 - accuracy: 0.9907 - val_loss: 0.0067 - val_accuracy: 0.9891\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0057 - accuracy: 0.9907 - val_loss: 0.0068 - val_accuracy: 0.9891\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0057 - accuracy: 0.9907 - val_loss: 0.0068 - val_accuracy: 0.9891\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0057 - accuracy: 0.9907 - val_loss: 0.0068 - val_accuracy: 0.9891\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0057 - accuracy: 0.9907 - val_loss: 0.0069 - val_accuracy: 0.9891\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0057 - accuracy: 0.9907 - val_loss: 0.0069 - val_accuracy: 0.9891\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0057 - accuracy: 0.9907 - val_loss: 0.0069 - val_accuracy: 0.9891\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0056 - accuracy: 0.9907 - val_loss: 0.0069 - val_accuracy: 0.9891\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0056 - accuracy: 0.9907 - val_loss: 0.0069 - val_accuracy: 0.9891\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0056 - accuracy: 0.9907 - val_loss: 0.0069 - val_accuracy: 0.9891\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0056 - accuracy: 0.9907 - val_loss: 0.0069 - val_accuracy: 0.9891\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0056 - accuracy: 0.9907 - val_loss: 0.0069 - val_accuracy: 0.9891\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0056 - accuracy: 0.9907 - val_loss: 0.0069 - val_accuracy: 0.9891\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0056 - accuracy: 0.9907 - val_loss: 0.0067 - val_accuracy: 0.9891\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0056 - accuracy: 0.9907 - val_loss: 0.0067 - val_accuracy: 0.9891\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0056 - accuracy: 0.9907 - val_loss: 0.0067 - val_accuracy: 0.9891\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0056 - accuracy: 0.9907 - val_loss: 0.0067 - val_accuracy: 0.9891\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0056 - accuracy: 0.9907 - val_loss: 0.0067 - val_accuracy: 0.9891\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0056 - accuracy: 0.9907 - val_loss: 0.0067 - val_accuracy: 0.9891\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0056 - accuracy: 0.9907 - val_loss: 0.0067 - val_accuracy: 0.9891\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0056 - accuracy: 0.9907 - val_loss: 0.0068 - val_accuracy: 0.9891\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0056 - accuracy: 0.9907 - val_loss: 0.0068 - val_accuracy: 0.9891\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0056 - accuracy: 0.9907 - val_loss: 0.0068 - val_accuracy: 0.9891\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0056 - accuracy: 0.9907 - val_loss: 0.0068 - val_accuracy: 0.9891\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0056 - accuracy: 0.9907 - val_loss: 0.0068 - val_accuracy: 0.9891\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0056 - accuracy: 0.9907 - val_loss: 0.0069 - val_accuracy: 0.9891\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0055 - accuracy: 0.9907 - val_loss: 0.0069 - val_accuracy: 0.9891\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0056 - accuracy: 0.9907 - val_loss: 0.0069 - val_accuracy: 0.9891\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0055 - accuracy: 0.9907 - val_loss: 0.0070 - val_accuracy: 0.9891\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0055 - accuracy: 0.9907 - val_loss: 0.0070 - val_accuracy: 0.9891\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0055 - accuracy: 0.9907 - val_loss: 0.0070 - val_accuracy: 0.9891\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0055 - accuracy: 0.9907 - val_loss: 0.0071 - val_accuracy: 0.9891\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0055 - accuracy: 0.9907 - val_loss: 0.0068 - val_accuracy: 0.9891\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0055 - accuracy: 0.9907 - val_loss: 0.0067 - val_accuracy: 0.9891\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0055 - accuracy: 0.9907 - val_loss: 0.0067 - val_accuracy: 0.9891\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0055 - accuracy: 0.9907 - val_loss: 0.0067 - val_accuracy: 0.9891\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0055 - accuracy: 0.9907 - val_loss: 0.0068 - val_accuracy: 0.9891\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0055 - accuracy: 0.9907 - val_loss: 0.0068 - val_accuracy: 0.9891\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0055 - accuracy: 0.9907 - val_loss: 0.0068 - val_accuracy: 0.9891\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0055 - accuracy: 0.9907 - val_loss: 0.0069 - val_accuracy: 0.9891\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0055 - accuracy: 0.9907 - val_loss: 0.0069 - val_accuracy: 0.9891\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0055 - accuracy: 0.9907 - val_loss: 0.0070 - val_accuracy: 0.9891\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0055 - accuracy: 0.9907 - val_loss: 0.0066 - val_accuracy: 0.9891\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0055 - accuracy: 0.9907 - val_loss: 0.0066 - val_accuracy: 0.9891\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0055 - accuracy: 0.9907 - val_loss: 0.0066 - val_accuracy: 0.9891\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0055 - accuracy: 0.9907 - val_loss: 0.0066 - val_accuracy: 0.9891\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0055 - accuracy: 0.9907 - val_loss: 0.0066 - val_accuracy: 0.9891\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0055 - accuracy: 0.9907 - val_loss: 0.0066 - val_accuracy: 0.9891\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0055 - accuracy: 0.9907 - val_loss: 0.0067 - val_accuracy: 0.9891\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0054 - accuracy: 0.9907 - val_loss: 0.0067 - val_accuracy: 0.9891\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0054 - accuracy: 0.9907 - val_loss: 0.0067 - val_accuracy: 0.9891\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0054 - accuracy: 0.9907 - val_loss: 0.0068 - val_accuracy: 0.9891\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0054 - accuracy: 0.9907 - val_loss: 0.0065 - val_accuracy: 0.9891\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0054 - accuracy: 0.9907 - val_loss: 0.0065 - val_accuracy: 0.9891\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0054 - accuracy: 0.9907 - val_loss: 0.0065 - val_accuracy: 0.9891\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0054 - accuracy: 0.9907 - val_loss: 0.0065 - val_accuracy: 0.9891\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0054 - accuracy: 0.9907 - val_loss: 0.0065 - val_accuracy: 0.9891\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0054 - accuracy: 0.9907 - val_loss: 0.0065 - val_accuracy: 0.9891\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0054 - accuracy: 0.9907 - val_loss: 0.0065 - val_accuracy: 0.9891\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0054 - accuracy: 0.9907 - val_loss: 0.0065 - val_accuracy: 0.9891\n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0054 - accuracy: 0.9907 - val_loss: 0.0065 - val_accuracy: 0.9891\n",
      "Epoch 100/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0054 - accuracy: 0.9907 - val_loss: 0.0065 - val_accuracy: 0.9891\n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0054 - accuracy: 0.9907 - val_loss: 0.0065 - val_accuracy: 0.9891\n",
      "Epoch 102/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0054 - accuracy: 0.9907 - val_loss: 0.0065 - val_accuracy: 0.9891\n",
      "Epoch 103/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0054 - accuracy: 0.9907 - val_loss: 0.0066 - val_accuracy: 0.9891\n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0054 - accuracy: 0.9907 - val_loss: 0.0066 - val_accuracy: 0.9891\n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0054 - accuracy: 0.9907 - val_loss: 0.0066 - val_accuracy: 0.9891\n",
      "Epoch 106/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0054 - accuracy: 0.9907 - val_loss: 0.0066 - val_accuracy: 0.9891\n",
      "Epoch 107/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0054 - accuracy: 0.9907 - val_loss: 0.0066 - val_accuracy: 0.9891\n",
      "Epoch 108/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0054 - accuracy: 0.9907 - val_loss: 0.0067 - val_accuracy: 0.9891\n",
      "Epoch 109/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0054 - accuracy: 0.9907 - val_loss: 0.0065 - val_accuracy: 0.9891\n",
      "Epoch 110/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0054 - accuracy: 0.9907 - val_loss: 0.0065 - val_accuracy: 0.9891\n",
      "Epoch 111/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0053 - accuracy: 0.9907 - val_loss: 0.0065 - val_accuracy: 0.9891\n",
      "Epoch 112/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0053 - accuracy: 0.9907 - val_loss: 0.0065 - val_accuracy: 0.9891\n",
      "Epoch 113/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0053 - accuracy: 0.9907 - val_loss: 0.0065 - val_accuracy: 0.9891\n",
      "Epoch 114/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0053 - accuracy: 0.9907 - val_loss: 0.0065 - val_accuracy: 0.9891\n",
      "Epoch 115/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0053 - accuracy: 0.9907 - val_loss: 0.0065 - val_accuracy: 0.9891\n",
      "Epoch 116/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0053 - accuracy: 0.9907 - val_loss: 0.0065 - val_accuracy: 0.9891\n",
      "Epoch 117/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0053 - accuracy: 0.9907 - val_loss: 0.0065 - val_accuracy: 0.9891\n",
      "Epoch 118/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0053 - accuracy: 0.9907 - val_loss: 0.0065 - val_accuracy: 0.9891\n",
      "Epoch 119/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0053 - accuracy: 0.9907 - val_loss: 0.0065 - val_accuracy: 0.9891\n",
      "Epoch 120/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0053 - accuracy: 0.9907 - val_loss: 0.0065 - val_accuracy: 0.9891\n",
      "Epoch 121/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0053 - accuracy: 0.9907 - val_loss: 0.0065 - val_accuracy: 0.9891\n",
      "Epoch 122/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0053 - accuracy: 0.9907 - val_loss: 0.0065 - val_accuracy: 0.9891\n",
      "Epoch 123/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0053 - accuracy: 0.9907 - val_loss: 0.0066 - val_accuracy: 0.9891\n",
      "Epoch 124/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0053 - accuracy: 0.9907 - val_loss: 0.0066 - val_accuracy: 0.9891\n",
      "Epoch 125/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0053 - accuracy: 0.9907 - val_loss: 0.0066 - val_accuracy: 0.9891\n",
      "Epoch 126/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0053 - accuracy: 0.9907 - val_loss: 0.0066 - val_accuracy: 0.9891\n",
      "Epoch 127/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0053 - accuracy: 0.9907 - val_loss: 0.0065 - val_accuracy: 0.9891\n",
      "Epoch 128/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0053 - accuracy: 0.9907 - val_loss: 0.0065 - val_accuracy: 0.9891\n",
      "Epoch 129/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0053 - accuracy: 0.9907 - val_loss: 0.0065 - val_accuracy: 0.9891\n",
      "Epoch 130/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0053 - accuracy: 0.9907 - val_loss: 0.0065 - val_accuracy: 0.9891\n",
      "Epoch 131/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0053 - accuracy: 0.9907 - val_loss: 0.0065 - val_accuracy: 0.9891\n",
      "Epoch 132/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0053 - accuracy: 0.9907 - val_loss: 0.0065 - val_accuracy: 0.9891\n",
      "Epoch 133/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0052 - accuracy: 0.9907 - val_loss: 0.0065 - val_accuracy: 0.9891\n",
      "Epoch 134/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0052 - accuracy: 0.9907 - val_loss: 0.0065 - val_accuracy: 0.9891\n",
      "Epoch 135/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0052 - accuracy: 0.9907 - val_loss: 0.0065 - val_accuracy: 0.9891\n",
      "Epoch 136/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0052 - accuracy: 0.9907 - val_loss: 0.0065 - val_accuracy: 0.9891\n",
      "Epoch 137/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0052 - accuracy: 0.9907 - val_loss: 0.0066 - val_accuracy: 0.9891\n",
      "Epoch 138/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0052 - accuracy: 0.9907 - val_loss: 0.0066 - val_accuracy: 0.9891\n",
      "Epoch 139/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0052 - accuracy: 0.9907 - val_loss: 0.0065 - val_accuracy: 0.9891\n",
      "Epoch 140/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0052 - accuracy: 0.9907 - val_loss: 0.0065 - val_accuracy: 0.9891\n",
      "Epoch 141/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0052 - accuracy: 0.9907 - val_loss: 0.0065 - val_accuracy: 0.9891\n",
      "Epoch 142/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0052 - accuracy: 0.9907 - val_loss: 0.0065 - val_accuracy: 0.9891\n",
      "Epoch 143/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0052 - accuracy: 0.9907 - val_loss: 0.0065 - val_accuracy: 0.9891\n",
      "Epoch 144/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0052 - accuracy: 0.9907 - val_loss: 0.0065 - val_accuracy: 0.9891\n",
      "Epoch 145/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0052 - accuracy: 0.9907 - val_loss: 0.0065 - val_accuracy: 0.9891\n",
      "Epoch 146/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0052 - accuracy: 0.9907 - val_loss: 0.0065 - val_accuracy: 0.9891\n",
      "Epoch 147/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0052 - accuracy: 0.9907 - val_loss: 0.0065 - val_accuracy: 0.9891\n",
      "Epoch 148/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0052 - accuracy: 0.9907 - val_loss: 0.0065 - val_accuracy: 0.9891\n",
      "Epoch 149/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0052 - accuracy: 0.9907 - val_loss: 0.0066 - val_accuracy: 0.9891\n",
      "Epoch 150/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0052 - accuracy: 0.9907 - val_loss: 0.0060 - val_accuracy: 0.9891\n",
      "Epoch 151/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0052 - accuracy: 0.9907 - val_loss: 0.0060 - val_accuracy: 0.9891\n",
      "Epoch 152/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0052 - accuracy: 0.9907 - val_loss: 0.0060 - val_accuracy: 0.9891\n",
      "Epoch 153/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0052 - accuracy: 0.9907 - val_loss: 0.0060 - val_accuracy: 0.9891\n",
      "Epoch 154/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0052 - accuracy: 0.9907 - val_loss: 0.0060 - val_accuracy: 0.9891\n",
      "Epoch 155/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0052 - accuracy: 0.9907 - val_loss: 0.0060 - val_accuracy: 0.9891\n",
      "Epoch 156/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0052 - accuracy: 0.9907 - val_loss: 0.0060 - val_accuracy: 0.9891\n",
      "Epoch 157/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0051 - accuracy: 0.9907 - val_loss: 0.0060 - val_accuracy: 0.9891\n",
      "Epoch 158/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0051 - accuracy: 0.9907 - val_loss: 0.0060 - val_accuracy: 0.9891\n",
      "Epoch 159/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0051 - accuracy: 0.9907 - val_loss: 0.0060 - val_accuracy: 0.9891\n",
      "Epoch 160/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0051 - accuracy: 0.9907 - val_loss: 0.0059 - val_accuracy: 0.9891\n",
      "Epoch 161/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0051 - accuracy: 0.9907 - val_loss: 0.0059 - val_accuracy: 0.9891\n",
      "Epoch 162/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0051 - accuracy: 0.9907 - val_loss: 0.0059 - val_accuracy: 0.9891\n",
      "Epoch 163/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0051 - accuracy: 0.9907 - val_loss: 0.0059 - val_accuracy: 0.9891\n",
      "Epoch 164/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0051 - accuracy: 0.9907 - val_loss: 0.0059 - val_accuracy: 0.9891\n",
      "Epoch 165/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0051 - accuracy: 0.9907 - val_loss: 0.0059 - val_accuracy: 0.9891\n",
      "Epoch 166/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0051 - accuracy: 0.9907 - val_loss: 0.0059 - val_accuracy: 0.9891\n",
      "Epoch 167/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0051 - accuracy: 0.9907 - val_loss: 0.0059 - val_accuracy: 0.9891\n",
      "Epoch 168/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0051 - accuracy: 0.9907 - val_loss: 0.0059 - val_accuracy: 0.9891\n",
      "Epoch 169/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0051 - accuracy: 0.9907 - val_loss: 0.0059 - val_accuracy: 0.9891\n",
      "Epoch 170/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0051 - accuracy: 0.9907 - val_loss: 0.0059 - val_accuracy: 0.9891\n",
      "Epoch 171/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0051 - accuracy: 0.9907 - val_loss: 0.0059 - val_accuracy: 0.9891\n",
      "Epoch 172/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0051 - accuracy: 0.9907 - val_loss: 0.0059 - val_accuracy: 0.9891\n",
      "Epoch 173/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0051 - accuracy: 0.9907 - val_loss: 0.0059 - val_accuracy: 0.9891\n",
      "Epoch 174/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0051 - accuracy: 0.9907 - val_loss: 0.0059 - val_accuracy: 0.9891\n",
      "Epoch 175/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0051 - accuracy: 0.9907 - val_loss: 0.0059 - val_accuracy: 0.9891\n",
      "Epoch 176/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0050 - accuracy: 0.9907 - val_loss: 0.0058 - val_accuracy: 0.9891\n",
      "Epoch 177/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0051 - accuracy: 0.9907 - val_loss: 0.0058 - val_accuracy: 0.9891\n",
      "Epoch 178/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0050 - accuracy: 0.9907 - val_loss: 0.0058 - val_accuracy: 0.9891\n",
      "Epoch 179/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0050 - accuracy: 0.9907 - val_loss: 0.0058 - val_accuracy: 0.9891\n",
      "Epoch 180/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0050 - accuracy: 0.9907 - val_loss: 0.0058 - val_accuracy: 0.9891\n",
      "Epoch 181/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0050 - accuracy: 0.9907 - val_loss: 0.0058 - val_accuracy: 0.9891\n",
      "Epoch 182/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0050 - accuracy: 0.9907 - val_loss: 0.0058 - val_accuracy: 0.9891\n",
      "Epoch 183/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0050 - accuracy: 0.9907 - val_loss: 0.0058 - val_accuracy: 0.9891\n",
      "Epoch 184/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0050 - accuracy: 0.9907 - val_loss: 0.0058 - val_accuracy: 0.9891\n",
      "Epoch 185/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0050 - accuracy: 0.9907 - val_loss: 0.0058 - val_accuracy: 0.9891\n",
      "Epoch 186/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0050 - accuracy: 0.9907 - val_loss: 0.0058 - val_accuracy: 0.9891\n",
      "Epoch 187/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0050 - accuracy: 0.9907 - val_loss: 0.0058 - val_accuracy: 0.9891\n",
      "Epoch 188/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0050 - accuracy: 0.9907 - val_loss: 0.0058 - val_accuracy: 0.9891\n",
      "Epoch 189/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0050 - accuracy: 0.9907 - val_loss: 0.0058 - val_accuracy: 0.9891\n",
      "Epoch 190/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0050 - accuracy: 0.9907 - val_loss: 0.0058 - val_accuracy: 0.9891\n",
      "Epoch 191/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0050 - accuracy: 0.9907 - val_loss: 0.0058 - val_accuracy: 0.9891\n",
      "Epoch 192/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0050 - accuracy: 0.9907 - val_loss: 0.0058 - val_accuracy: 0.9891\n",
      "Epoch 193/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0050 - accuracy: 0.9907 - val_loss: 0.0058 - val_accuracy: 0.9891\n",
      "Epoch 194/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0049 - accuracy: 0.9907 - val_loss: 0.0058 - val_accuracy: 0.9891\n",
      "Epoch 195/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0049 - accuracy: 0.9907 - val_loss: 0.0058 - val_accuracy: 0.9891\n",
      "Epoch 196/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0049 - accuracy: 0.9907 - val_loss: 0.0058 - val_accuracy: 0.9891\n",
      "Epoch 197/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0049 - accuracy: 0.9907 - val_loss: 0.0058 - val_accuracy: 0.9891\n",
      "Epoch 198/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0049 - accuracy: 0.9907 - val_loss: 0.0057 - val_accuracy: 0.9891\n",
      "Epoch 199/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0049 - accuracy: 0.9907 - val_loss: 0.0057 - val_accuracy: 0.9891\n",
      "Epoch 200/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0049 - accuracy: 0.9907 - val_loss: 0.0057 - val_accuracy: 0.9891\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=200, batch_size=64, validation_data=(X_validation, y_validation))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.005710979457944632\n",
      "Test accuracy: 0.989130437374115\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_validation, y_validation, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[[[ 0.00000000e+00],\n         [ 6.42535385e-02],\n         [ 6.30018462e-02],\n         [-4.38092308e-03],\n         [-3.58818462e-02],\n         [-2.39907692e-02],\n         [ 5.21538462e-03],\n         [ 3.02492308e-02],\n         [ 7.51015385e-03],\n         [-1.64806154e-02],\n         [-4.19316923e-02],\n         [-3.10836923e-02],\n         [ 6.67569231e-03],\n         [ 2.14873846e-02],\n         [ 1.64806154e-02],\n         [-6.25846154e-04],\n         [ 1.96098462e-02],\n         [ 5.67433846e-02],\n         [ 1.00344000e-01],\n         [ 1.10983385e-01],\n         [ 5.11107692e-02],\n         [ 6.25846154e-04],\n         [-1.06393846e-02],\n         [ 1.50203077e-02],\n         [ 3.10836923e-02],\n         [ 5.21538462e-03],\n         [-1.31427692e-02],\n         [-3.96369231e-03],\n         [ 5.88295385e-02],\n         [ 1.27672615e-01],\n         [ 1.59799385e-01],\n         [ 1.47699692e-01],\n         [ 8.07341538e-02],\n         [ 5.27796923e-02],\n         [ 6.80086154e-02],\n         [ 8.59495385e-02],\n         [ 7.63532308e-02],\n         [ 1.73150769e-02],\n         [-1.12652308e-02],\n         [-5.84123077e-03],\n         [ 3.71335385e-02],\n         [ 9.38769231e-02],\n         [ 9.05390769e-02],\n         [ 5.46572308e-02],\n         [ 1.18910769e-02],\n         [ 1.06393846e-02],\n         [ 4.10972308e-02],\n         [ 5.17366154e-02],\n         [ 2.81630769e-02],\n         [-3.48387692e-02],\n         [-5.31969231e-02],\n         [-2.52424615e-02],\n         [ 1.14738462e-02],\n         [ 4.08886154e-02],\n         [ 2.54510769e-02],\n         [ 6.25846154e-04],\n         [-1.64806154e-02],\n         [ 5.21538462e-03],\n         [ 3.75507692e-02],\n         [ 1.41858462e-02],\n         [-2.89975385e-02],\n         [-7.05120000e-02],\n         [-6.09156923e-02],\n         [-5.00676923e-03],\n         [ 3.69249231e-02],\n         [ 5.15280000e-02],\n         [ 1.66892308e-02],\n         [-8.13600000e-03],\n         [ 2.08615385e-03],\n         [ 2.04443077e-02],\n         [ 3.50473846e-02],\n         [-4.17230769e-04],\n         [-4.29747692e-02],\n         [-3.90110769e-02],\n         [ 2.08615385e-03],\n         [ 6.23760000e-02],\n         [ 8.38633846e-02],\n         [ 4.88160000e-02],\n         [-2.50338462e-03],\n         [-3.37956923e-02],\n         [-3.46301538e-02],\n         [-3.98455385e-02],\n         [-7.63532308e-02],\n         [-1.37894769e-01],\n         [-1.75654154e-01],\n         [-1.48116923e-01],\n         [-7.78135385e-02],\n         [-1.20996923e-02],\n         [ 9.80492308e-03],\n         [-2.08615385e-03],\n         [-7.51015385e-03],\n         [ 5.84123077e-03],\n         [ 1.14738462e-02],\n         [-1.81495385e-02],\n         [-9.07476923e-02],\n         [-1.52915077e-01],\n         [-1.46030769e-01],\n         [-8.40720000e-02],\n         [-2.44080000e-02],\n         [ 8.34461538e-04],\n         [-5.00676923e-03],\n         [-1.75236923e-02],\n         [ 1.31427692e-02],\n         [ 6.48793846e-02],\n         [ 7.65618462e-02],\n         [ 2.50338462e-02],\n         [-5.54916923e-02],\n         [-8.84529231e-02],\n         [-4.58953846e-02],\n         [ 2.35735385e-02],\n         [ 6.86344615e-02],\n         [ 6.13329231e-02],\n         [ 9.59630769e-03],\n         [-1.87753846e-02],\n         [-6.46707692e-03],\n         [ 1.08480000e-02],\n         [-3.75507692e-03],\n         [-4.56867692e-02],\n         [-6.34190769e-02],\n         [-3.27526154e-02],\n         [ 4.13058462e-02],\n         [ 1.10357538e-01],\n         [ 1.34556923e-01],\n         [ 1.20788308e-01],\n         [ 9.95095385e-02],\n         [ 1.03473231e-01],\n         [ 1.13278154e-01],\n         [ 9.45027692e-02],\n         [ 3.79680000e-02],\n         [-2.08615385e-02],\n         [-2.52424615e-02],\n         [ 3.65076923e-02],\n         [ 1.28924308e-01],\n         [ 1.79826462e-01],\n         [ 1.73568000e-01],\n         [ 1.52289231e-01],\n         [ 1.35808615e-01],\n         [ 1.34974154e-01],\n         [ 1.20162462e-01],\n         [ 7.17636923e-02],\n         [ 2.08615385e-03],\n         [-5.15280000e-02],\n         [-2.25304615e-02],\n         [ 5.15280000e-02],\n         [ 1.01178462e-01],\n         [ 1.16407385e-01],\n         [ 1.03473231e-01],\n         [ 1.03264615e-01],\n         [ 1.10983385e-01],\n         [ 9.78406154e-02],\n         [ 4.61040000e-02],\n         [-5.15280000e-02],\n         [-1.21414154e-01],\n         [-1.21831385e-01],\n         [-6.15415385e-02],\n         [ 2.16960000e-02],\n         [ 6.48793846e-02],\n         [ 5.17366154e-02],\n         [ 7.92738462e-03],\n         [-4.38092308e-03],\n         [ 2.79544615e-02],\n         [ 5.86209231e-02],\n         [ 3.96369231e-02],\n         [-2.00270769e-02],\n         [-4.67298462e-02],\n         [-2.41993846e-02],\n         [ 3.17095385e-02],\n         [ 6.63396923e-02],\n         [ 4.08886154e-02],\n         [-1.66892308e-03],\n         [-1.81495385e-02],\n         [ 1.14738462e-02],\n         [ 3.65076923e-02],\n         [ 9.38769231e-03],\n         [-3.56732308e-02],\n         [-6.42535385e-02],\n         [-3.60904615e-02],\n         [ 4.40178462e-02],\n         [ 9.97181538e-02],\n         [ 1.23500308e-01],\n         [ 9.70061538e-02],\n         [ 6.96775385e-02],\n         [ 8.40720000e-02],\n         [ 8.55323077e-02],\n         [ 6.50880000e-02],\n         [-1.25169231e-02],\n         [-8.19858462e-02],\n         [-1.02012923e-01],\n         [-6.73827692e-02],\n         [ 1.04307692e-03],\n         [ 2.39907692e-02],\n         [ 2.19046154e-02],\n         [-5.84123077e-03],\n         [-6.88430769e-03],\n         [ 2.50338462e-02],\n         [ 3.08750769e-02],\n         [-8.34461538e-03],\n         [-7.96910769e-02],\n         [-1.03264615e-01],\n         [-6.38363077e-02],\n         [ 7.30153846e-03],\n         [ 5.27796923e-02],\n         [ 2.94147692e-02],\n         [-2.25304615e-02],\n         [-5.13193846e-02],\n         [-4.02627692e-02],\n         [-3.54646154e-03],\n         [ 7.71876923e-03],\n         [-1.37686154e-02],\n         [-5.15280000e-02],\n         [-6.50880000e-02],\n         [-1.77323077e-02],\n         [ 2.25304615e-02],\n         [ 3.37956923e-02],\n         [ 4.79815385e-03],\n         [-3.60904615e-02],\n         [-1.87753846e-02],\n         [ 1.96098462e-02],\n         [ 5.21538462e-02],\n         [ 4.10972308e-02],\n         [-2.06529231e-02],\n         [-5.54916923e-02],\n         [-3.71335385e-02],\n         [ 1.50203077e-02],\n         [ 5.90381538e-02],\n         [ 4.90246154e-02],\n         [ 1.75236923e-02],\n         [ 2.16960000e-02],\n         [ 5.25710769e-02],\n         [ 7.51015385e-02],\n         [ 6.82172308e-02],\n         [ 2.10701538e-02],\n         [-2.81630769e-02],\n         [-1.58547692e-02],\n         [ 2.96233846e-02],\n         [ 7.48929231e-02],\n         [ 7.57273846e-02],\n         [ 2.37821538e-02],\n         [-6.67569231e-03],\n         [-1.04307692e-02],\n         [ 1.35600000e-02],\n         [ 1.83581538e-02],\n         [-1.66892308e-02],\n         [-5.79950769e-02],\n         [-7.57273846e-02],\n         [-3.88024615e-02],\n         [-3.12923077e-03],\n         [ 4.79815385e-03],\n         [-1.56461538e-02],\n         [-4.27661538e-02],\n         [-3.37956923e-02],\n         [ 2.08615385e-03],\n         [ 3.94283077e-02],\n         [ 3.27526154e-02],\n         [-2.08615385e-02],\n         [-5.54916923e-02],\n         [-3.62990769e-02],\n         [ 4.38092308e-03],\n         [ 2.21132308e-02],\n         [ 5.21538462e-03],\n         [-3.33784615e-02],\n         [-5.79950769e-02],\n         [-3.46301538e-02],\n         [ 1.62720000e-02],\n         [ 4.54781538e-02],\n         [ 3.71335385e-02],\n         [ 2.08615385e-04],\n         [-1.89840000e-02],\n         [-6.25846154e-04],\n         [ 2.94147692e-02],\n         [ 4.10972308e-02],\n         [ 1.41858462e-02],\n         [ 2.92061538e-03],\n         [ 2.71200000e-02],\n         [ 6.59224615e-02],\n         [ 8.67840000e-02],\n         [ 5.38227692e-02],\n         [ 4.58953846e-03],\n         [-3.04578462e-02],\n         [-8.55323077e-03],\n         [ 6.21673846e-02],\n         [ 9.67975385e-02],\n         [ 8.38633846e-02],\n         [ 4.61040000e-02],\n         [ 4.10972308e-02],\n         [ 7.67704615e-02],\n         [ 1.00761231e-01],\n         [ 8.46978462e-02],\n         [ 2.41993846e-02],\n         [-1.43944615e-02],\n         [-1.00135385e-02],\n         [ 2.21132308e-02],\n         [ 5.42400000e-02],\n         [ 4.61040000e-02],\n         [ 1.48116923e-02],\n         [ 2.29476923e-03],\n         [ 3.56732308e-02],\n         [ 9.51286154e-02],\n         [ 1.14947077e-01],\n         [ 6.69655385e-02],\n         [ 1.04307692e-03],\n         [-2.52424615e-02],\n         [ 2.50338462e-03],\n         [ 4.56867692e-02],\n         [ 6.73827692e-02],\n         [ 3.50473846e-02],\n         [-1.41858462e-02],\n         [-3.46301538e-02],\n         [-2.21132308e-02],\n         [ 1.62720000e-02],\n         [ 1.50203077e-02],\n         [-1.54375385e-02],\n         [-3.88024615e-02],\n         [-2.77458462e-02],\n         [ 2.62855385e-02],\n         [ 5.31969231e-02],\n         [ 4.08886154e-02],\n         [ 5.42400000e-03],\n         [-1.79409231e-02],\n         [ 1.52289231e-02],\n         [ 5.82036923e-02],\n         [ 6.57138462e-02],\n         [ 1.60633846e-02],\n         [-5.42400000e-02],\n         [-6.69655385e-02],\n         [-1.87753846e-02],\n         [ 5.69520000e-02],\n         [ 1.05142154e-01],\n         [ 1.08897231e-01],\n         [ 9.76320000e-02],\n         [ 8.38633846e-02],\n         [ 7.92738462e-02],\n         [ 6.94689231e-02],\n         [ 2.58683077e-02],\n         [-2.79544615e-02],\n         [-5.82036923e-02],\n         [-2.83716923e-02],\n         [ 4.50609231e-02],\n         [ 9.09563077e-02],\n         [ 7.34326154e-02],\n         [ 8.13600000e-03],\n         [-2.81630769e-02],\n         [-1.50203077e-02],\n         [ 2.33649231e-02],\n         [ 5.09021538e-02],\n         [ 2.89975385e-02],\n         [-1.52289231e-02],\n         [-3.33784615e-02],\n         [-2.50338462e-03],\n         [ 4.52695385e-02],\n         [ 4.63126154e-02],\n         [ 1.00135385e-02],\n         [-1.52289231e-02],\n         [-1.62720000e-02],\n         [ 4.79815385e-03],\n         [ 1.33513846e-02],\n         [-5.21538462e-03],\n         [-3.40043077e-02],\n         [-4.77729231e-02],\n         [-6.46707692e-03],\n         [ 5.13193846e-02],\n         [ 6.63396923e-02],\n         [ 3.83852308e-02],\n         [-1.85667692e-02],\n         [-2.79544615e-02],\n         [ 2.58683077e-02],\n         [ 7.59360000e-02],\n         [ 9.53372308e-02],\n         [ 6.52966154e-02],\n         [ 2.71200000e-02],\n         [ 1.23083077e-02],\n         [ 3.42129231e-02],\n         [ 7.23895385e-02],\n         [ 6.82172308e-02],\n         [ 4.81901538e-02],\n         [ 3.35870769e-02],\n         [ 3.81766154e-02],\n         [ 6.11243077e-02],\n         [ 5.73692308e-02],\n         [ 3.75507692e-02],\n         [ 1.87753846e-03],\n         [-1.52289231e-02],\n         [ 2.48252308e-02],\n         [ 5.75778462e-02],\n         [ 6.21673846e-02],\n         [ 3.17095385e-02],\n         [-1.94012308e-02],\n         [-4.86073846e-02],\n         [-5.67433846e-02],\n         [-4.10972308e-02],\n         [-4.61040000e-02],\n         [-7.46843077e-02],\n         [-8.97046154e-02],\n         [-7.09292308e-02],\n         [-1.87753846e-02],\n         [ 2.08615385e-03],\n         [-4.38092308e-03],\n         [-3.52560000e-02],\n         [-6.48793846e-02],\n         [-4.65212308e-02],\n         [-2.87889231e-02],\n         [-2.33649231e-02],\n         [-5.82036923e-02],\n         [-1.07228308e-01],\n         [-1.06602462e-01],\n         [-7.59360000e-02],\n         [-2.29476923e-02],\n         [ 4.38092308e-03],\n         [-1.85667692e-02],\n         [-4.52695385e-02],\n         [-4.86073846e-02],\n         [-2.27390769e-02],\n         [ 3.33784615e-03],\n         [ 8.34461538e-03],\n         [-8.13600000e-03],\n         [-3.06664615e-02],\n         [-2.16960000e-02],\n         [ 7.09292308e-03],\n         [ 3.06664615e-02],\n         [ 1.52289231e-02],\n         [-2.21132308e-02],\n         [-2.37821538e-02],\n         [ 8.13600000e-03],\n         [ 5.52830769e-02],\n         [ 7.28067692e-02],\n         [ 5.67433846e-02],\n         [ 4.04713846e-02],\n         [ 4.48523077e-02],\n         [ 7.11378462e-02],\n         [ 8.32375385e-02],\n         [ 6.90516923e-02],\n         [ 3.06664615e-02],\n         [ 9.38769231e-03],\n         [ 1.91926154e-02],\n         [ 5.50744615e-02],\n         [ 1.02221538e-01],\n         [ 1.13695385e-01],\n         [ 1.07854154e-01],\n         [ 9.95095385e-02],\n         [ 1.14947077e-01],\n         [ 1.34556923e-01],\n         [ 1.07436923e-01],\n         [ 4.63126154e-02],\n         [-2.14873846e-02],\n         [-4.38092308e-02],\n         [-2.56596923e-02],\n         [ 2.92061538e-03],\n         [ 3.19181538e-02],\n         [ 2.94147692e-02],\n         [ 1.71064615e-02],\n         [ 2.56596923e-02],\n         [ 4.04713846e-02],\n         [ 5.04849231e-02],\n         [ 2.46166154e-02],\n         [-2.46166154e-02],\n         [-4.65212308e-02],\n         [-2.64941538e-02],\n         [ 2.02356923e-02],\n         [ 5.90381538e-02],\n         [ 7.90652308e-02],\n         [ 6.44621538e-02],\n         [ 4.15144615e-02],\n         [ 4.06800000e-02],\n         [ 3.37956923e-02],\n         [ 3.12923077e-03],\n         [-5.92467692e-02],\n         [-1.06811077e-01],\n         [-9.47113846e-02],\n         [-2.81630769e-02],\n         [ 6.88430769e-02],\n         [ 1.26838154e-01],\n         [ 1.27046769e-01],\n         [ 1.10983385e-01],\n         [ 1.14738462e-01],\n         [ 1.25377846e-01],\n         [ 1.02012923e-01],\n         [ 4.17230769e-02],\n         [-3.81766154e-02],\n         [-7.80221538e-02],\n         [-5.61175385e-02],\n         [-7.51015385e-03],\n         [ 3.71335385e-02],\n         [ 4.67298462e-02],\n         [ 4.33920000e-02],\n         [ 4.63126154e-02],\n         [ 6.55052308e-02],\n         [ 6.48793846e-02],\n         [ 2.71200000e-03],\n         [-5.82036923e-02],\n         [-9.88836923e-02],\n         [-9.19993846e-02],\n         [-2.21132308e-02],\n         [ 3.96369231e-02],\n         [ 7.34326154e-02],\n         [ 4.98590769e-02],\n         [-2.08615385e-03],\n         [-2.12787692e-02],\n         [-4.06800000e-02],\n         [-6.71741538e-02],\n         [-1.07228308e-01],\n         [-1.41649846e-01],\n         [-1.29341538e-01],\n         [-7.46843077e-02],\n         [-3.96369231e-03],\n         [ 3.73421538e-02],\n         [ 4.10972308e-02],\n         [ 2.58683077e-02],\n         [ 2.04443077e-02],\n         [ 4.23489231e-02],\n         [ 3.65076923e-02],\n         [-1.75236923e-02],\n         [-9.11649231e-02],\n         [-1.38103385e-01],\n         [-1.02847385e-01],\n         [-1.79409231e-02],\n         [ 8.05255385e-02],\n         [ 1.36017231e-01],\n         [ 1.08062769e-01],\n         [ 6.86344615e-02],\n         [ 5.90381538e-02],\n         [ 5.67433846e-02],\n         [ 1.81495385e-02],\n         [-6.00812308e-02],\n         [-1.08271385e-01],\n         [-1.00552615e-01],\n         [-5.19452308e-02],\n         [ 2.12787692e-02],\n         [ 5.59089231e-02],\n         [ 5.67433846e-02],\n         [ 5.50744615e-02],\n         [ 5.92467692e-02],\n         [ 7.30153846e-02],\n         [ 5.02763077e-02],\n         [-7.92738462e-03],\n         [-7.09292308e-02],\n         [-9.59630769e-02],\n         [-4.25575385e-02],\n         [ 6.13329231e-02],\n         [ 1.25169231e-01],\n         [ 1.14947077e-01],\n         [ 7.69790769e-02],\n         [ 2.67027692e-02],\n         [-5.42400000e-03],\n         [-2.73286154e-02],\n         [-6.67569231e-02],\n         [-1.02221538e-01],\n         [-1.24960615e-01],\n         [-8.07341538e-02],\n         [ 2.64941538e-02],\n         [ 1.04933538e-01],\n         [ 1.14321231e-01],\n         [ 7.92738462e-02],\n         [ 4.83987692e-02],\n         [ 3.27526154e-02],\n         [ 1.50203077e-02],\n         [-6.25846154e-03],\n         [-4.46436923e-02],\n         [-9.36683077e-02],\n         [-9.30424615e-02],\n         [-3.27526154e-02],\n         [ 4.61040000e-02],\n         [ 9.55458462e-02],\n         [ 9.07476923e-02],\n         [ 6.15415385e-02],\n         [ 4.77729231e-02],\n         [ 5.73692308e-02],\n         [ 6.15415385e-02],\n         [ 7.71876923e-03],\n         [-8.72012308e-02],\n         [-1.43110154e-01],\n         [-1.16824615e-01],\n         [-3.02492308e-02],\n         [ 6.15415385e-02],\n         [ 1.13278154e-01],\n         [ 1.11400615e-01],\n         [ 9.30424615e-02],\n         [ 8.99132308e-02],\n         [ 9.09563077e-02],\n         [ 5.96640000e-02],\n         [-3.96369231e-03],\n         [-4.52695385e-02],\n         [-2.48252308e-02],\n         [ 4.86073846e-02],\n         [ 1.17867692e-01],\n         [ 1.39772308e-01],\n         [ 1.08897231e-01],\n         [ 5.48658462e-02],\n         [ 2.27390769e-02],\n         [ 3.10836923e-02],\n         [ 4.17230769e-02],\n         [ 6.25846154e-03],\n         [-3.92196923e-02],\n         [-5.23624615e-02],\n         [-6.25846154e-04],\n         [ 9.51286154e-02],\n         [ 1.36225846e-01],\n         [ 1.14738462e-01],\n         [ 6.44621538e-02],\n         [ 1.66892308e-02],\n         [ 2.10701538e-02],\n         [ 4.23489231e-02],\n         [ 3.77593846e-02],\n         [ 6.88430769e-03],\n         [-3.75507692e-02],\n         [-3.88024615e-02],\n         [ 1.04307692e-03],\n         [ 4.48523077e-02],\n         [ 5.92467692e-02],\n         [ 3.10836923e-02],\n         [ 1.83581538e-02],\n         [ 3.31698462e-02],\n         [ 7.17636923e-02],\n         [ 9.13735385e-02],\n         [ 4.31833846e-02],\n         [-2.96233846e-02],\n         [-6.13329231e-02],\n         [-3.21267692e-02],\n         [ 1.52289231e-02],\n         [ 5.00676923e-02],\n         [ 4.06800000e-02],\n         [-8.34461538e-03],\n         [-2.10701538e-02],\n         [-2.50338462e-03],\n         [ 4.79815385e-03],\n         [-1.66892308e-02],\n         [-7.13464615e-02],\n         [-8.74098462e-02],\n         [-3.88024615e-02],\n         [ 4.42264615e-02],\n         [ 1.14947077e-01],\n         [ 1.15572923e-01],\n         [ 6.59224615e-02],\n         [ 1.35600000e-02],\n         [-3.12923077e-03],\n         [ 1.58547692e-02],\n         [ 2.96233846e-02],\n         [ 1.08480000e-02],\n         [-2.69113846e-02],\n         [-3.48387692e-02],\n         [-4.17230769e-04],\n         [ 3.85938462e-02],\n         [ 4.67298462e-02],\n         [-1.46030769e-03],\n         [-4.81901538e-02],\n         [-4.52695385e-02],\n         [-4.79815385e-03],\n         [ 4.86073846e-02],\n         [ 4.94418462e-02],\n         [ 1.23083077e-02],\n         [-3.04578462e-02],\n         [-3.19181538e-02],\n         [-1.87753846e-03],\n         [-6.46707692e-03],\n         [-4.06800000e-02],\n         [-9.55458462e-02],\n         [-1.05768000e-01],\n         [-6.11243077e-02],\n         [-1.37686154e-02],\n         [-9.59630769e-03],\n         [-7.09292308e-02],\n         [-1.31636308e-01],\n         [-1.40189538e-01],\n         [-8.53236923e-02],\n         [-1.87753846e-03],\n         [ 3.94283077e-02],\n         [ 2.71200000e-02],\n         [ 1.04307692e-03],\n         [-1.66892308e-03],\n         [ 8.55323077e-03],\n         [-1.87753846e-03],\n         [-5.42400000e-02],\n         [-1.25377846e-01],\n         [-1.55835692e-01],\n         [-1.24126154e-01],\n         [-4.08886154e-02],\n         [ 2.54510769e-02],\n         [ 2.27390769e-02],\n         [ 1.04307692e-02],\n         [ 1.71064615e-02],\n         [ 4.48523077e-02],\n         [ 7.34326154e-02],\n         [ 6.44621538e-02],\n         [ 2.54510769e-02],\n         [-1.56461538e-02],\n         [-6.88430769e-03],\n         [ 3.04578462e-02],\n         [ 5.46572308e-02],\n         [ 3.69249231e-02],\n         [-2.21132308e-02],\n         [-4.33920000e-02],\n         [-1.46030769e-02],\n         [ 4.54781538e-02],\n         [ 1.04933538e-01],\n         [ 1.06393846e-01],\n         [ 6.92603077e-02],\n         [ 4.58953846e-02],\n         [ 7.23895385e-02],\n         [ 1.19536615e-01],\n         [ 1.35182769e-01],\n         [ 1.20371077e-01],\n         [ 9.65889231e-02],\n         [ 9.51286154e-02],\n         [ 1.27255385e-01],\n         [ 1.62302769e-01],\n         [ 1.44570462e-01],\n         [ 6.94689231e-02],\n         [ 5.42400000e-03],\n         [ 2.92061538e-03],\n         [ 5.09021538e-02],\n         [ 1.02847385e-01],\n         [ 1.08271385e-01],\n         [ 7.78135385e-02],\n         [ 6.80086154e-02],\n         [ 7.55187692e-02],\n         [ 9.01218462e-02],\n         [ 7.32240000e-02],\n         [ 1.77323077e-02],\n         [-2.39907692e-02],\n         [-3.48387692e-02],\n         [ 5.63261538e-03],\n         [ 6.57138462e-02],\n         [ 9.63803077e-02],\n         [ 8.40720000e-02],\n         [ 5.50744615e-02],\n         [ 4.71470769e-02],\n         [ 6.48793846e-02],\n         [ 7.36412308e-02],\n         [ 3.75507692e-02],\n         [-1.39772308e-02],\n         [-5.50744615e-02],\n         [-3.88024615e-02],\n         [ 2.21132308e-02],\n         [ 4.58953846e-02],\n         [ 4.04713846e-02],\n         [ 1.29341538e-02],\n         [ 1.79409231e-02],\n         [ 6.25846154e-02],\n         [ 8.99132308e-02],\n         [ 9.24166154e-02],\n         [ 3.50473846e-02],\n         [-1.98184615e-02],\n         [-1.25169231e-02],\n         [ 2.33649231e-02],\n         [ 5.31969231e-02],\n         [ 4.06800000e-02],\n         [ 3.96369231e-03],\n         [-2.04443077e-02],\n         [-1.43944615e-02],\n         [ 1.81495385e-02],\n         [ 2.79544615e-02],\n         [-2.92061538e-03],\n         [-6.55052308e-02],\n         [-1.06811077e-01],\n         [-9.40855385e-02],\n         [-6.73827692e-02],\n         [-3.79680000e-02],\n         [-4.71470769e-02],\n         [-6.04984615e-02],\n         [-3.50473846e-02],\n         [ 8.34461538e-04],\n         [ 2.62855385e-02],\n         [-8.97046154e-03],\n         [-7.28067692e-02],\n         [-1.22457231e-01],\n         [-1.34765538e-01],\n         [-1.04099077e-01],\n         [-8.01083077e-02],\n         [-7.40584615e-02],\n         [-9.49200000e-02],\n         [-1.05976615e-01],\n         [-6.63396923e-02],\n         [-1.56461538e-02],\n         [ 1.87753846e-02],\n         [ 3.96369231e-03],\n         [-3.23353846e-02],\n         [-2.87889231e-02],\n         [-1.66892308e-03],\n         [ 4.88160000e-02],\n         [ 6.67569231e-02],\n         [ 4.00541538e-02],\n         [ 6.46707692e-03],\n         [-2.79544615e-02],\n         [ 0.00000000e+00],\n         [ 2.77458462e-02],\n         [ 3.40043077e-02],\n         [ 3.83852308e-02],\n         [ 3.56732308e-02],\n         [ 7.71876923e-02],\n         [ 1.15155692e-01],\n         [ 1.34974154e-01],\n         [ 9.70061538e-02],\n         [ 2.35735385e-02],\n         [ 1.12652308e-02],\n         [ 3.25440000e-02],\n         [ 8.34461538e-02],\n         [ 1.05350769e-01],\n         [ 9.36683077e-02],\n         [ 8.11513846e-02],\n         [ 3.88024615e-02],\n         [ 3.77593846e-02],\n         [ 3.69249231e-02],\n         [ 9.17907692e-03],\n         [-2.14873846e-02],\n         [-4.40178462e-02],\n         [ 1.75236923e-02],\n         [ 9.24166154e-02],\n         [ 1.27046769e-01],\n         [ 1.23083077e-01],\n         [ 7.38498462e-02],\n         [ 5.04849231e-02],\n         [ 4.83987692e-02],\n         [ 6.30018462e-02],\n         [ 6.48793846e-02],\n         [ 9.59630769e-03],\n         [-3.19181538e-02],\n         [-3.92196923e-02],\n         [-1.20996923e-02],\n         [ 2.81630769e-02],\n         [ 5.98726154e-02],\n         [ 6.82172308e-02],\n         [ 5.75778462e-02],\n         [ 9.38769231e-02],\n         [ 1.29341538e-01],\n         [ 1.40606769e-01],\n         [ 1.10983385e-01],\n         [ 2.94147692e-02],\n         [-1.62720000e-02],\n         [-2.35735385e-02],\n         [ 1.75236923e-02],\n         [ 6.63396923e-02],\n         [ 7.57273846e-02],\n         [ 6.11243077e-02],\n         [ 4.23489231e-02],\n         [ 7.17636923e-02],\n         [ 9.05390769e-02],\n         [ 7.28067692e-02],\n         [ 2.46166154e-02],\n         [-2.27390769e-02],\n         [ 1.04307692e-03],\n         [ 5.42400000e-02],\n         [ 1.02430154e-01],\n         [ 1.05768000e-01],\n         [ 5.90381538e-02],\n         [ 2.44080000e-02],\n         [ 1.04307692e-02],\n         [ 3.17095385e-02],\n         [ 4.63126154e-02],\n         [ 1.25169231e-03],\n         [-4.98590769e-02],\n         [-7.69790769e-02],\n         [-3.50473846e-02],\n         [ 3.54646154e-02],\n         [ 5.36141538e-02],\n         [ 3.62990769e-02],\n         [-1.66892308e-02],\n         [-3.69249231e-02],\n         [-1.98184615e-02],\n         [-2.92061538e-03],\n         [-1.16824615e-02],\n         [-6.94689231e-02],\n         [-1.02847385e-01],\n         [-9.30424615e-02],\n         [-3.90110769e-02],\n         [ 1.66892308e-02],\n         [ 3.06664615e-02],\n         [ 6.67569231e-03],\n         [-3.69249231e-02],\n         [-3.62990769e-02],\n         [-1.71064615e-02],\n         [-1.56461538e-02],\n         [-4.08886154e-02],\n         [-8.59495385e-02],\n         [-9.42941538e-02],\n         [-4.63126154e-02],\n         [ 1.94012308e-02],\n         [ 5.57003077e-02],\n         [ 4.71470769e-02],\n         [ 1.79409231e-02],\n         [ 1.14738462e-02],\n         [ 4.13058462e-02],\n         [ 6.90516923e-02],\n         [ 4.48523077e-02],\n         [-8.97046154e-03],\n         [-4.46436923e-02],\n         [-3.23353846e-02],\n         [ 1.23083077e-02],\n         [ 4.75643077e-02],\n         [ 5.88295385e-02],\n         [ 3.69249231e-02],\n         [ 2.52424615e-02],\n         [ 3.10836923e-02],\n         [ 3.56732308e-02],\n         [ 2.12787692e-02],\n         [-3.31698462e-02],\n         [-7.94824615e-02],\n         [-6.98861538e-02],\n         [-6.67569231e-03],\n         [ 7.28067692e-02],\n         [ 1.13904000e-01],\n         [ 8.86615385e-02],\n         [ 3.98455385e-02],\n         [ 1.62720000e-02],\n         [ 1.52289231e-02],\n         [ 1.46030769e-03],\n         [-4.81901538e-02],\n         [-1.09105846e-01],\n         [-1.37268923e-01],\n         [-1.06602462e-01],\n         [-2.37821538e-02],\n         [ 5.19452308e-02],\n         [ 7.65618462e-02],\n         [ 6.25846154e-02],\n         [ 4.96504615e-02],\n         [ 6.98861538e-02],\n         [ 7.57273846e-02],\n         [ 3.40043077e-02],\n         [-3.37956923e-02],\n         [-9.45027692e-02],\n         [-9.57544615e-02],\n         [-4.17230769e-02],\n         [ 1.62720000e-02],\n         [ 2.96233846e-02],\n         [-6.25846154e-03],\n         [-4.29747692e-02],\n         [-4.00541538e-02],\n         [-2.08615385e-03],\n         [ 7.92738462e-03],\n         [-3.06664615e-02],\n         [-8.72012308e-02],\n         [-1.20579692e-01],\n         [-8.44892308e-02],\n         [-5.84123077e-03],\n         [ 6.15415385e-02],\n         [ 8.09427692e-02],\n         [ 6.13329231e-02],\n         [ 5.13193846e-02],\n         [ 5.36141538e-02],\n         [ 4.98590769e-02],\n         [ 1.16824615e-02],\n         [-6.73827692e-02],\n         [-1.35182769e-01],\n         [-1.45404923e-01],\n         [-9.32510769e-02],\n         [-2.46166154e-02],\n         [ 9.38769231e-03],\n         [ 1.46030769e-02],\n         [ 1.66892308e-02],\n         [ 4.94418462e-02],\n         [ 9.88836923e-02],\n         [ 1.07645538e-01],\n         [ 5.92467692e-02],\n         [-2.16960000e-02],\n         [-5.04849231e-02],\n         [-1.06393846e-02],\n         [ 5.36141538e-02],\n         [ 9.01218462e-02],\n         [ 5.84123077e-02],\n         [ 2.04443077e-02],\n         [ 0.00000000e+00],\n         [ 8.55323077e-03],\n         [ 1.96098462e-02],\n         [-2.48252308e-02],\n         [-7.65618462e-02],\n         [-1.00135385e-01],\n         [-5.17366154e-02],\n         [ 4.06800000e-02],\n         [ 1.01178462e-01],\n         [ 1.32262154e-01],\n         [ 1.13904000e-01],\n         [ 8.63667692e-02],\n         [ 8.32375385e-02],\n         [ 8.07341538e-02],\n         [ 5.46572308e-02],\n         [-1.66892308e-02],\n         [-6.98861538e-02],\n         [-7.55187692e-02],\n         [-2.37821538e-02],\n         [ 5.98726154e-02],\n         [ 9.65889231e-02],\n         [ 9.57544615e-02],\n         [ 7.55187692e-02],\n         [ 6.94689231e-02],\n         [ 9.61716923e-02],\n         [ 1.11817846e-01],\n         [ 8.72012308e-02],\n         [ 2.06529231e-02],\n         [-2.69113846e-02],\n         [-1.29341538e-02],\n         [ 3.08750769e-02],\n         [ 6.15415385e-02],\n         [ 5.77864615e-02],\n         [ 4.44350769e-02],\n         [ 5.06935385e-02],\n         [ 8.11513846e-02],\n         [ 1.06811077e-01],\n         [ 7.98996923e-02],\n         [ 9.17907692e-03],\n         [-5.50744615e-02],\n         [-6.80086154e-02],\n         [-2.56596923e-02],\n         [ 2.41993846e-02],\n         [ 3.48387692e-02],\n         [ 6.25846154e-03],\n         [-1.87753846e-02],\n         [-1.94012308e-02],\n         [-5.84123077e-03],\n         [-1.71064615e-02],\n         [-7.25981538e-02],\n         [-1.21205538e-01],\n         [-1.25377846e-01],\n         [-6.69655385e-02],\n         [ 1.87753846e-02],\n         [ 5.98726154e-02],\n         [ 5.11107692e-02],\n         [ 1.37686154e-02],\n         [-5.21538462e-03],\n         [ 3.75507692e-03],\n         [-3.96369231e-03],\n         [-3.67163077e-02],\n         [-9.82578462e-02],\n         [-1.34974154e-01],\n         [-1.12860923e-01],\n         [-5.23624615e-02],\n         [ 2.50338462e-03],\n         [-3.33784615e-03],\n         [-3.94283077e-02],\n         [-6.15415385e-02],\n         [-3.77593846e-02],\n         [ 9.80492308e-03],\n         [ 2.00270769e-02],\n         [-1.43944615e-02],\n         [-5.82036923e-02],\n         [-4.81901538e-02],\n         [ 4.58953846e-03],\n         [ 5.46572308e-02],\n         [ 7.40584615e-02],\n         [ 2.46166154e-02],\n         [-2.14873846e-02],\n         [-1.52289231e-02],\n         [ 1.66892308e-02],\n         [ 3.75507692e-02],\n         [-2.08615385e-03],\n         [-6.32104615e-02],\n         [-9.67975385e-02],\n         [-6.48793846e-02],\n         [ 1.06393846e-02],\n         [ 6.52966154e-02],\n         [ 7.23895385e-02],\n         [ 4.19316923e-02],\n         [ 4.58953846e-02],\n         [ 8.07341538e-02],\n         [ 1.19328000e-01],\n         [ 1.16198769e-01],\n         [ 5.06935385e-02],\n         [ 1.25169231e-03],\n         [-1.33513846e-02],\n         [ 1.89840000e-02],\n         [ 5.92467692e-02],\n         [ 6.80086154e-02],\n         [ 5.06935385e-02],\n         [ 1.35600000e-02],\n         [ 1.81495385e-02],\n         [ 3.40043077e-02],\n         [ 3.02492308e-02],\n         [-1.87753846e-03],\n         [-6.17501538e-02],\n         [-7.21809231e-02],\n         [-2.69113846e-02],\n         [ 5.00676923e-02],\n         [ 9.57544615e-02],\n         [ 7.17636923e-02],\n         [ 4.15144615e-02],\n         [ 2.56596923e-02],\n         [ 4.98590769e-02],\n         [ 7.86480000e-02],\n         [ 5.31969231e-02],\n         [ 1.31427692e-02],\n         [-2.71200000e-02],\n         [-1.04307692e-02],\n         [ 5.38227692e-02],\n         [ 8.17772308e-02],\n         [ 5.59089231e-02],\n         [-1.46030769e-03],\n         [-1.71064615e-02],\n         [ 1.58547692e-02],\n         [ 6.71741538e-02],\n         [ 9.05390769e-02],\n         [ 6.59224615e-02],\n         [ 3.69249231e-02],\n         [ 2.35735385e-02],\n         [ 5.77864615e-02],\n         [ 1.00135385e-01],\n         [ 1.09940308e-01],\n         [ 9.51286154e-02],\n         [ 5.29883077e-02],\n         [ 4.52695385e-02],\n         [ 7.05120000e-02],\n         [ 7.69790769e-02],\n         [ 5.04849231e-02],\n         [-5.63261538e-03],\n         [-3.10836923e-02],\n         [-1.41858462e-02],\n         [ 3.94283077e-02],\n         [ 1.11817846e-01],\n         [ 1.24543385e-01],\n         [ 9.72147692e-02],\n         [ 8.01083077e-02],\n         [ 1.05559385e-01],\n         [ 1.30593231e-01],\n         [ 8.40720000e-02],\n         [ 3.12923077e-03],\n         [-5.65347692e-02],\n         [-5.17366154e-02],\n         [ 1.06393846e-02],\n         [ 8.01083077e-02],\n         [ 9.55458462e-02],\n         [ 4.96504615e-02],\n         [ 4.58953846e-03],\n         [ 8.34461538e-04],\n         [ 2.21132308e-02],\n         [ 4.21403077e-02],\n         [ 3.46301538e-02],\n         [ 9.59630769e-03],\n         [ 8.97046154e-03],\n         [ 4.54781538e-02],\n         [ 9.30424615e-02],\n         [ 9.76320000e-02],\n         [ 5.79950769e-02],\n         [ 0.00000000e+00],\n         [-2.56596923e-02],\n         [ 1.46030769e-03],\n         [ 3.67163077e-02],\n         [ 4.96504615e-02],\n         [ 2.46166154e-02],\n         [ 4.17230769e-03],\n         [ 1.56461538e-02],\n         [ 4.86073846e-02],\n         [ 8.17772308e-02],\n         [ 7.34326154e-02],\n         [ 4.44350769e-02],\n         [ 2.19046154e-02],\n         [ 2.85803077e-02],\n         [ 4.29747692e-02],\n         [ 1.64806154e-02],\n         [-3.06664615e-02],\n         [-8.28203077e-02],\n         [-1.06393846e-01],\n         [-7.44756923e-02],\n         [-1.68978462e-02],\n         [ 2.44080000e-02],\n         [ 3.15009231e-02],\n         [ 2.56596923e-02],\n         [ 5.15280000e-02],\n         [ 1.06185231e-01],\n         [ 1.29341538e-01],\n         [ 9.95095385e-02],\n         [ 2.50338462e-02],\n         [-3.92196923e-02],\n         [-4.40178462e-02],\n         [-2.10701538e-02],\n         [-2.29476923e-03],\n         [-2.64941538e-02],\n         [-7.30153846e-02],\n         [-8.76184615e-02],\n         [-6.63396923e-02],\n         [-1.62720000e-02],\n         [ 2.77458462e-02],\n         [ 3.23353846e-02],\n         [ 1.81495385e-02],\n         [ 2.39907692e-02],\n         [ 6.11243077e-02],\n         [ 1.05350769e-01],\n         [ 1.00552615e-01],\n         [ 4.69384615e-02],\n         [-8.97046154e-03],\n         [-2.67027692e-02],\n         [-8.55323077e-03],\n         [-2.71200000e-03],\n         [-1.64806154e-02],\n         [-6.00812308e-02],\n         [-9.05390769e-02],\n         [-6.73827692e-02],\n         [-2.21132308e-02],\n         [ 1.58547692e-02],\n         [-6.04984615e-03],\n         [-4.10972308e-02],\n         [-3.79680000e-02],\n         [-1.14738462e-02],\n         [ 3.10836923e-02],\n         [ 3.42129231e-02],\n         [ 5.21538462e-03],\n         [-2.52424615e-02],\n         [-3.37956923e-02],\n         [ 7.92738462e-03],\n         [ 3.96369231e-02],\n         [ 3.00406154e-02],\n         [-9.80492308e-03],\n         [-4.23489231e-02],\n         [-3.92196923e-02],\n         [-1.81495385e-02],\n         [ 1.16824615e-02],\n         [ 3.12923077e-03],\n         [-2.35735385e-02],\n         [-1.18910769e-02],\n         [ 2.58683077e-02],\n         [ 8.24030769e-02],\n         [ 1.04099077e-01],\n         [ 6.25846154e-02],\n         [-8.34461538e-04],\n         [-5.96640000e-02],\n         [-7.46843077e-02],\n         [-6.25846154e-02],\n         [-6.48793846e-02],\n         [-7.71876923e-02],\n         [-7.96910769e-02],\n         [-3.71335385e-02],\n         [ 1.60633846e-02],\n         [ 4.61040000e-02],\n         [ 4.31833846e-02],\n         [-8.34461538e-04],\n         [-3.10836923e-02],\n         [-2.60769231e-02],\n         [-2.08615385e-03],\n         [ 1.16824615e-02],\n         [-4.58953846e-03],\n         [-1.81495385e-02],\n         [-8.13600000e-03],\n         [ 2.67027692e-02],\n         [ 6.07070769e-02],\n         [ 5.02763077e-02],\n         [-4.17230769e-04],\n         [-4.81901538e-02],\n         [-4.75643077e-02],\n         [-2.08615385e-03],\n         [ 4.13058462e-02],\n         [ 7.13464615e-02],\n         [ 7.71876923e-02],\n         [ 6.86344615e-02],\n         [ 8.53236923e-02],\n         [ 1.06185231e-01],\n         [ 1.16407385e-01],\n         [ 8.57409231e-02],\n         [ 2.58683077e-02],\n         [-8.55323077e-03],\n         [-4.17230769e-04],\n         [ 3.27526154e-02],\n         [ 2.98320000e-02],\n         [ 1.06393846e-02],\n         [ 1.87753846e-03],\n         [ 1.33513846e-02],\n         [ 4.54781538e-02],\n         [ 6.94689231e-02],\n         [ 6.71741538e-02],\n         [ 3.08750769e-02],\n         [-2.29476923e-03],\n         [ 5.42400000e-03],\n         [ 4.44350769e-02],\n         [ 6.38363077e-02],\n         [ 5.48658462e-02],\n         [ 2.94147692e-02],\n         [ 1.23083077e-02],\n         [ 2.29476923e-02],\n         [ 2.44080000e-02],\n         [ 1.00135385e-02],\n         [-3.02492308e-02],\n         [-9.11649231e-02],\n         [-1.12860923e-01],\n         [-7.05120000e-02],\n         [ 1.66892308e-03],\n         [ 5.54916923e-02],\n         [ 6.73827692e-02],\n         [ 5.44486154e-02],\n         [ 4.86073846e-02],\n         [ 5.21538462e-02],\n         [ 4.10972308e-02],\n         [-2.92061538e-03],\n         [-6.96775385e-02],\n         [-1.29967385e-01],\n         [-1.33096615e-01],\n         [-9.78406154e-02],\n         [-6.42535385e-02],\n         [-5.34055385e-02],\n         [-7.03033846e-02],\n         [-6.71741538e-02],\n         [-4.23489231e-02],\n         [-8.13600000e-03],\n         [-1.35600000e-02],\n         [-6.36276923e-02],\n         [-1.12860923e-01],\n         [-1.29341538e-01],\n         [-8.80356923e-02],\n         [-3.81766154e-02],\n         [-5.21538462e-03],\n         [-1.04307692e-02],\n         [-2.98320000e-02],\n         [-1.89840000e-02],\n         [-2.71200000e-03],\n         [ 1.66892308e-03],\n         [-3.85938462e-02],\n         [-1.02012923e-01],\n         [-1.18910769e-01],\n         [-8.76184615e-02],\n         [-2.83716923e-02],\n         [ 1.85667692e-02],\n         [ 1.46030769e-02],\n         [-7.09292308e-03],\n         [-7.51015385e-03],\n         [ 2.33649231e-02],\n         [ 3.50473846e-02],\n         [-1.00135385e-02],\n         [-7.78135385e-02],\n         [-1.22874462e-01],\n         [-1.05350769e-01],\n         [-4.42264615e-02],\n         [ 2.48252308e-02],\n         [ 6.84258462e-02],\n         [ 5.98726154e-02],\n         [ 2.77458462e-02],\n         [ 1.23083077e-02],\n         [ 2.31563077e-02],\n         [ 1.41858462e-02],\n         [-2.33649231e-02],\n         [-6.88430769e-02],\n         [-9.61716923e-02],\n         [-6.11243077e-02],\n         [ 3.75507692e-03],\n         [ 6.82172308e-02],\n         [ 1.04516308e-01],\n         [ 9.74233846e-02],\n         [ 9.13735385e-02],\n         [ 1.04933538e-01],\n         [ 1.10566154e-01],\n         [ 6.50880000e-02],\n         [-8.76184615e-03],\n         [-5.48658462e-02],\n         [-3.54646154e-02],\n         [ 3.48387692e-02],\n         [ 9.09563077e-02],\n         [ 1.08897231e-01],\n         [ 9.88836923e-02],\n         [ 9.67975385e-02],\n         [ 1.15781538e-01],\n         [ 1.23500308e-01],\n         [ 1.11817846e-01],\n         [ 6.96775385e-02],\n         [ 2.19046154e-02],\n         [ 7.09292308e-03],\n         [ 4.00541538e-02],\n         [ 1.03681846e-01],\n         [ 1.33096615e-01],\n         [ 1.20788308e-01],\n         [ 9.30424615e-02],\n         [ 9.11649231e-02],\n         [ 1.02012923e-01],\n         [ 7.73963077e-02],\n         [ 2.94147692e-02],\n         [-1.96098462e-02],\n         [-3.92196923e-02],\n         [ 5.42400000e-03],\n         [ 1.02221538e-01],\n         [ 1.72316308e-01],\n         [ 1.71690462e-01],\n         [ 1.18493538e-01],\n         [ 7.94824615e-02],\n         [ 9.30424615e-02],\n         [ 1.04099077e-01],\n         [ 8.63667692e-02],\n         [ 3.21267692e-02],\n         [-1.81495385e-02],\n         [-2.44080000e-02],\n         [ 9.38769231e-03],\n         [ 6.63396923e-02],\n         [ 9.19993846e-02],\n         [ 8.94960000e-02],\n         [ 8.03169231e-02],\n         [ 9.82578462e-02],\n         [ 1.34765538e-01],\n         [ 1.31844923e-01],\n         [ 6.59224615e-02],\n         [-2.87889231e-02],\n         [-7.23895385e-02],\n         [-4.08886154e-02],\n         [ 2.56596923e-02],\n         [ 5.75778462e-02],\n         [ 4.65212308e-02],\n         [ 1.14738462e-02],\n         [-9.38769231e-03],\n         [ 1.58547692e-02],\n         [ 4.94418462e-02],\n         [ 4.19316923e-02],\n         [-1.75236923e-02],\n         [-6.63396923e-02],\n         [-5.73692308e-02],\n         [ 4.17230769e-04],\n         [ 6.19587692e-02],\n         [ 7.80221538e-02],\n         [ 5.34055385e-02],\n         [ 2.33649231e-02],\n         [ 2.31563077e-02],\n         [ 3.69249231e-02],\n         [ 2.08615385e-02],\n         [-2.19046154e-02],\n         [-8.30289231e-02],\n         [-9.86750769e-02],\n         [-3.46301538e-02],\n         [ 4.77729231e-02],\n         [ 9.45027692e-02],\n         [ 6.07070769e-02],\n         [ 6.88430769e-03],\n         [-9.59630769e-03],\n         [-3.12923077e-03],\n         [ 1.08480000e-02],\n         [-2.25304615e-02],\n         [-8.74098462e-02],\n         [-1.18702154e-01],\n         [-9.47113846e-02],\n         [-2.77458462e-02],\n         [ 2.50338462e-02],\n         [ 2.19046154e-02],\n         [-2.08615385e-02],\n         [-4.77729231e-02],\n         [-3.75507692e-02],\n         [-1.89840000e-02],\n         [-1.60633846e-02],\n         [-4.88160000e-02],\n         [-8.15686154e-02],\n         [-6.38363077e-02],\n         [-7.71876923e-03],\n         [ 6.04984615e-02],\n         [ 9.80492308e-02],\n         [ 7.48929231e-02],\n         [ 2.77458462e-02],\n         [ 1.87753846e-02],\n         [ 5.79950769e-02],\n         [ 7.71876923e-02],\n         [ 4.36006154e-02],\n         [-5.42400000e-03],\n         [-3.35870769e-02],\n         [-1.43944615e-02],\n         [ 4.17230769e-02],\n         [ 1.00135385e-01],\n         [ 1.10983385e-01],\n         [ 7.11378462e-02],\n         [ 5.04849231e-02],\n         [ 6.88430769e-02],\n         [ 8.21944615e-02],\n         [ 5.57003077e-02],\n         [-3.96369231e-03],\n         [-4.92332308e-02],\n         [-2.73286154e-02],\n         [ 3.90110769e-02],\n         [ 8.78270769e-02],\n         [ 8.38633846e-02],\n         [ 4.38092308e-02],\n         [ 9.17907692e-03],\n         [-4.17230769e-03],\n         [ 1.43944615e-02],\n         [ 1.96098462e-02],\n         [-1.89840000e-02],\n         [-5.90381538e-02],\n         [-5.52830769e-02],\n         [-6.25846154e-04],\n         [ 6.57138462e-02],\n         [ 8.82443077e-02],\n         [ 5.50744615e-02],\n         [ 1.58547692e-02],\n         [-3.54646154e-03],\n         [ 5.21538462e-03],\n         [ 3.06664615e-02],\n         [ 3.25440000e-02],\n         [-3.12923077e-03],\n         [-5.86209231e-02],\n         [-5.96640000e-02],\n         [ 2.92061538e-03],\n         [ 5.54916923e-02],\n         [ 4.94418462e-02],\n         [-5.00676923e-03],\n         [-3.60904615e-02],\n         [-1.77323077e-02],\n         [ 2.04443077e-02],\n         [ 2.10701538e-02],\n         [-2.14873846e-02],\n         [-6.78000000e-02],\n         [-8.69926154e-02],\n         [-4.00541538e-02],\n         [ 1.87753846e-02],\n         [ 4.19316923e-02],\n         [ 3.02492308e-02],\n         [ 3.96369231e-03],\n         [ 1.87753846e-02],\n         [ 5.13193846e-02],\n         [ 6.46707692e-02],\n         [ 4.06800000e-02],\n         [-1.18910769e-02],\n         [-4.48523077e-02],\n         [-1.29341538e-02],\n         [ 4.46436923e-02],\n         [ 7.96910769e-02],\n         [ 8.59495385e-02],\n         [ 5.21538462e-02],\n         [ 3.83852308e-02],\n         [ 5.52830769e-02],\n         [ 9.13735385e-02],\n         [ 9.53372308e-02],\n         [ 4.50609231e-02],\n         [ 9.59630769e-03],\n         [ 2.19046154e-02],\n         [ 9.13735385e-02],\n         [ 1.35391385e-01],\n         [ 1.25377846e-01],\n         [ 8.78270769e-02],\n         [ 3.92196923e-02],\n         [ 2.64941538e-02],\n         [ 3.06664615e-02],\n         [ 2.81630769e-02],\n         [-3.12923077e-03],\n         [-5.54916923e-02],\n         [-6.59224615e-02],\n         [-1.52289231e-02],\n         [ 6.21673846e-02],\n         [ 1.05976615e-01],\n         [ 8.88701538e-02],\n         [ 4.92332308e-02],\n         [ 2.37821538e-02],\n         [ 3.23353846e-02],\n         [ 4.19316923e-02],\n         [ 1.87753846e-03],\n         [-5.69520000e-02],\n         [-1.02847385e-01],\n         [-9.99267692e-02],\n         [-4.29747692e-02],\n         [ 1.25169231e-03],\n         [ 3.75507692e-03],\n         [-2.29476923e-02],\n         [-2.85803077e-02],\n         [ 5.42400000e-03],\n         [ 4.46436923e-02],\n         [ 4.98590769e-02],\n         [-1.27255385e-02],\n         [-7.86480000e-02],\n         [-9.61716923e-02],\n         [-6.82172308e-02],\n         [-1.06393846e-02],\n         [ 1.89840000e-02],\n         [ 1.77323077e-02],\n         [-4.38092308e-03],\n         [-1.81495385e-02],\n         [ 9.17907692e-03],\n         [ 2.48252308e-02],\n         [-1.75236923e-02],\n         [-9.70061538e-02],\n         [-1.46030769e-01],\n         [-1.30593231e-01],\n         [-8.13600000e-02],\n         [-3.62990769e-02],\n         [-2.21132308e-02],\n         [-3.77593846e-02],\n         [-4.69384615e-02],\n         [-2.77458462e-02],\n         [-3.75507692e-03],\n         [-2.60769231e-02],\n         [-8.11513846e-02],\n         [-1.13695385e-01],\n         [-1.00552615e-01],\n         [-4.08886154e-02],\n         [ 1.41858462e-02],\n         [ 3.42129231e-02],\n         [ 9.59630769e-03],\n         [-2.44080000e-02],\n         [-2.08615385e-02],\n         [ 3.75507692e-03],\n         [ 2.02356923e-02],\n         [-1.04307692e-02],\n         [-5.34055385e-02],\n         [-8.86615385e-02],\n         [-8.07341538e-02],\n         [-1.73150769e-02],\n         [ 1.39772308e-02],\n         [ 1.10566154e-02],\n         [-6.25846154e-04],\n         [ 9.17907692e-03],\n         [ 4.67298462e-02],\n         [ 7.76049231e-02],\n         [ 7.63532308e-02],\n         [ 2.16960000e-02],\n         [-3.50473846e-02],\n         [-5.38227692e-02],\n         [-2.67027692e-02],\n         [ 8.55323077e-03],\n         [-3.33784615e-03],\n         [-2.41993846e-02],\n         [-2.06529231e-02],\n         [ 1.23083077e-02],\n         [ 6.80086154e-02],\n         [ 8.88701538e-02],\n         [ 5.00676923e-02],\n         [-3.96369231e-03],\n         [-1.64806154e-02],\n         [ 1.46030769e-02],\n         [ 6.40449231e-02],\n         [ 9.80492308e-02],\n         [ 8.61581538e-02],\n         [ 6.44621538e-02],\n         [ 6.15415385e-02],\n         [ 8.61581538e-02],\n         [ 1.02847385e-01],\n         [ 6.57138462e-02],\n         [ 1.98184615e-02],\n         [ 5.84123077e-03],\n         [ 3.71335385e-02],\n         [ 7.88566154e-02],\n         [ 1.08480000e-01],\n         [ 1.05350769e-01],\n         [ 5.50744615e-02],\n         [ 1.58547692e-02],\n         [ 2.21132308e-02],\n         [ 7.28067692e-02],\n         [ 8.09427692e-02],\n         [ 3.62990769e-02],\n         [ 6.25846154e-03],\n         [-1.25169231e-03],\n         [ 2.35735385e-02],\n         [ 5.94553846e-02],\n         [ 7.92738462e-02],\n         [ 5.48658462e-02],\n         [ 1.98184615e-02],\n         [ 1.20996923e-02],\n         [ 2.75372308e-02],\n         [ 3.77593846e-02],\n         [ 1.83581538e-02],\n         [-1.41858462e-02],\n         [-4.50609231e-02],\n         [-4.27661538e-02],\n         [ 0.00000000e+00],\n         [ 3.33784615e-02],\n         [ 3.52560000e-02],\n         [ 2.92061538e-02],\n         [ 2.92061538e-02],\n         [ 5.71606154e-02],\n         [ 8.67840000e-02],\n         [ 8.53236923e-02],\n         [ 3.92196923e-02],\n         [-1.23083077e-02],\n         [-1.10566154e-02],\n         [ 1.96098462e-02],\n         [ 5.71606154e-02],\n         [ 4.79815385e-02],\n         [ 7.09292308e-03],\n         [-1.04307692e-02],\n         [-4.38092308e-03],\n         [ 3.37956923e-02],\n         [ 6.71741538e-02],\n         [ 7.15550769e-02],\n         [ 4.44350769e-02],\n         [ 1.83581538e-02],\n         [ 3.46301538e-02],\n         [ 6.44621538e-02],\n         [ 7.15550769e-02],\n         [ 3.17095385e-02],\n         [-9.17907692e-03],\n         [-1.23083077e-02],\n         [ 8.55323077e-03],\n         [ 3.90110769e-02],\n         [ 3.02492308e-02],\n         [-6.46707692e-03],\n         [-2.58683077e-02],\n         [-3.21267692e-02],\n         [-7.92738462e-03],\n         [ 2.10701538e-02],\n         [ 9.17907692e-03],\n         [-2.35735385e-02],\n         [-4.86073846e-02],\n         [-2.94147692e-02],\n         [ 1.52289231e-02],\n         [ 4.15144615e-02],\n         [ 2.96233846e-02],\n         [-1.29341538e-02],\n         [-2.77458462e-02],\n         [-2.14873846e-02],\n         [-2.12787692e-02],\n         [-3.25440000e-02],\n         [-7.03033846e-02],\n         [-9.82578462e-02],\n         [-8.92873846e-02],\n         [-3.46301538e-02],\n         [ 2.87889231e-02],\n         [ 4.81901538e-02],\n         [ 3.44215385e-02],\n         [-3.54646154e-03],\n         [-1.79409231e-02],\n         [-1.00135385e-02],\n         [-3.27526154e-02],\n         [-7.69790769e-02],\n         [-1.27046769e-01],\n         [-1.34348308e-01],\n         [-7.76049231e-02],\n         [ 3.12923077e-03],\n         [ 6.96775385e-02],\n         [ 6.25846154e-02],\n         [ 2.48252308e-02],\n         [ 2.81630769e-02],\n         [ 5.48658462e-02],\n         [ 8.03169231e-02],\n         [ 6.36276923e-02],\n         [ 2.19046154e-02],\n         [-1.87753846e-02],\n         [-2.60769231e-02],\n         [ 2.33649231e-02],\n         [ 7.19723077e-02],\n         [ 8.53236923e-02],\n         [ 6.78000000e-02],\n         [ 6.00812308e-02],\n         [ 7.71876923e-02],\n         [ 9.99267692e-02],\n         [ 8.44892308e-02],\n         [ 2.77458462e-02],\n         [-2.25304615e-02],\n         [-3.92196923e-02],\n         [-1.46030769e-03],\n         [ 5.13193846e-02],\n         [ 7.05120000e-02],\n         [ 5.36141538e-02],\n         [ 1.27255385e-02],\n         [-5.21538462e-03],\n         [ 7.09292308e-03],\n         [ 0.00000000e+00],\n         [-2.71200000e-02],\n         [-6.52966154e-02],\n         [-8.55323077e-02],\n         [-4.63126154e-02],\n         [ 2.83716923e-02],\n         [ 9.55458462e-02],\n         [ 1.23291692e-01],\n         [ 1.13695385e-01],\n         [ 9.59630769e-02],\n         [ 1.02638769e-01],\n         [ 1.06811077e-01],\n         [ 8.42806154e-02],\n         [ 3.90110769e-02],\n         [-1.12652308e-02],\n         [-1.31427692e-02],\n         [ 3.50473846e-02],\n         [ 9.99267692e-02],\n         [ 1.31219077e-01],\n         [ 1.08688615e-01],\n         [ 7.51015385e-02],\n         [ 7.00947692e-02],\n         [ 8.19858462e-02],\n         [ 8.13600000e-02],\n         [ 4.75643077e-02],\n         [ 2.71200000e-03],\n         [-2.16960000e-02],\n         [-2.29476923e-03],\n         [ 6.36276923e-02],\n         [ 1.03264615e-01],\n         [ 1.11817846e-01],\n         [ 1.12026462e-01],\n         [ 1.16824615e-01],\n         [ 1.30593231e-01],\n         [ 1.07228308e-01],\n         [ 4.71470769e-02],\n         [-4.69384615e-02],\n         [-1.18493538e-01],\n         [-1.20162462e-01],\n         [-5.79950769e-02],\n         [ 2.67027692e-02],\n         [ 5.50744615e-02],\n         [ 5.46572308e-02],\n         [ 5.23624615e-02],\n         [ 7.32240000e-02],\n         [ 1.17450462e-01],\n         [ 1.16616000e-01],\n         [ 5.86209231e-02],\n         [-2.02356923e-02],\n         [-6.13329231e-02],\n         [-4.19316923e-02],\n         [ 1.39772308e-02],\n         [ 6.84258462e-02],\n         [ 7.51015385e-02],\n         [ 4.63126154e-02],\n         [ 2.77458462e-02],\n         [ 2.58683077e-02],\n         [ 2.33649231e-02],\n         [-2.25304615e-02],\n         [-8.30289231e-02],\n         [-1.14947077e-01],\n         [-8.65753846e-02],\n         [-6.67569231e-03],\n         [ 5.23624615e-02],\n         [ 7.53101538e-02],\n         [ 4.92332308e-02],\n         [ 3.40043077e-02],\n         [ 6.30018462e-02],\n         [ 9.74233846e-02],\n         [ 9.30424615e-02],\n         [ 4.58953846e-03],\n         [-7.57273846e-02],\n         [-9.45027692e-02],\n         [-5.19452308e-02],\n         [ 3.46301538e-02],\n         [ 7.30153846e-02],\n         [ 6.98861538e-02],\n         [ 5.57003077e-02],\n         [ 4.92332308e-02],\n         [ 5.50744615e-02],\n         [ 2.83716923e-02],\n         [-1.31427692e-02],\n         [-7.19723077e-02],\n         [-1.00344000e-01],\n         [-5.23624615e-02],\n         [ 3.12923077e-02],\n         [ 1.06811077e-01],\n         [ 1.14738462e-01],\n         [ 9.36683077e-02],\n         [ 7.46843077e-02],\n         [ 6.55052308e-02],\n         [ 7.05120000e-02],\n         [ 3.56732308e-02],\n         [-4.17230769e-02],\n         [-1.21622769e-01],\n         [-1.30176000e-01],\n         [-6.17501538e-02],\n         [ 5.00676923e-03],\n         [ 3.75507692e-02],\n         [ 1.50203077e-02],\n         [-1.91926154e-02],\n         [-2.19046154e-02],\n         [-8.76184615e-03],\n         [-7.51015385e-03],\n         [-5.75778462e-02],\n         [-1.22040000e-01],\n         [-1.38729231e-01],\n         [-8.94960000e-02],\n         [-8.97046154e-03],\n         [ 4.83987692e-02],\n         [ 5.31969231e-02],\n         [ 2.10701538e-02],\n         [ 2.71200000e-03],\n         [ 1.56461538e-02],\n         [ 2.48252308e-02],\n         [-1.04307692e-02],\n         [-7.59360000e-02],\n         [-1.35600000e-01],\n         [-1.15781538e-01],\n         [-2.21132308e-02],\n         [ 7.63532308e-02],\n         [ 1.31844923e-01],\n         [ 1.10566154e-01],\n         [ 8.63667692e-02],\n         [ 8.09427692e-02],\n         [ 6.88430769e-02],\n         [ 3.25440000e-02],\n         [-4.77729231e-02],\n         [-1.11192000e-01],\n         [-1.08271385e-01],\n         [-5.90381538e-02],\n         [ 2.08615385e-04],\n         [ 2.64941538e-02],\n         [-6.25846154e-04],\n         [-4.58953846e-02],\n         [-7.11378462e-02],\n         [-5.57003077e-02],\n         [-3.42129231e-02],\n         [-4.73556923e-02],\n         [-8.01083077e-02],\n         [-1.03056000e-01],\n         [-7.84393846e-02],\n         [-2.98320000e-02],\n         [ 5.42400000e-03],\n         [ 1.02221538e-02],\n         [-1.96098462e-02],\n         [-4.23489231e-02],\n         [-2.31563077e-02],\n         [ 1.52289231e-02],\n         [ 1.52289231e-02],\n         [-4.10972308e-02],\n         [-1.09731692e-01],\n         [-1.25377846e-01],\n         [-8.09427692e-02],\n         [-1.18910769e-02],\n         [ 1.43944615e-02],\n         [ 7.30153846e-03],\n         [-1.43944615e-02],\n         [-1.08480000e-02],\n         [ 4.50609231e-02],\n         [ 5.75778462e-02],\n         [ 3.62990769e-02],\n         [-1.94012308e-02],\n         [-4.77729231e-02],\n         [ 2.08615385e-04],\n         [ 6.19587692e-02],\n         [ 1.11817846e-01],\n         [ 9.26252308e-02],\n         [ 4.98590769e-02],\n         [ 3.17095385e-02],\n         [ 6.19587692e-02],\n         [ 1.06185231e-01],\n         [ 7.88566154e-02],\n         [ 3.94283077e-02],\n         [ 1.46030769e-03],\n         [-1.48116923e-02],\n         [ 3.69249231e-02],\n         [ 7.82307692e-02],\n         [ 8.82443077e-02],\n         [ 7.15550769e-02],\n         [ 4.67298462e-02],\n         [ 7.57273846e-02],\n         [ 1.01387077e-01],\n         [ 1.03681846e-01],\n         [ 7.76049231e-02],\n         [ 1.46030769e-02],\n         [-9.80492308e-03],\n         [ 2.08615385e-04],\n         [ 4.06800000e-02],\n         [ 5.54916923e-02],\n         [ 2.77458462e-02],\n         [-1.25169231e-03],\n         [-1.43944615e-02],\n         [ 2.73286154e-02],\n         [ 6.23760000e-02],\n         [ 5.46572308e-02],\n         [ 3.75507692e-03],\n         [-5.11107692e-02],\n         [-5.48658462e-02],\n         [-2.19046154e-02],\n         [ 1.60633846e-02],\n         [ 1.04307692e-02],\n         [-1.64806154e-02],\n         [-1.91926154e-02],\n         [-3.96369231e-03],\n         [ 2.64941538e-02],\n         [ 3.67163077e-02],\n         [-1.83581538e-02],\n         [-8.78270769e-02],\n         [-1.09523077e-01],\n         [-6.88430769e-02],\n         [ 1.46030769e-03],\n         [ 2.21132308e-02],\n         [-4.17230769e-04],\n         [-1.66892308e-02],\n         [-7.71876923e-03],\n         [ 3.08750769e-02],\n         [ 5.13193846e-02],\n         [ 2.89975385e-02],\n         [-5.42400000e-03],\n         [-3.31698462e-02],\n         [-2.19046154e-02],\n         [ 2.64941538e-02],\n         [ 5.46572308e-02],\n         [ 4.08886154e-02],\n         [ 7.30153846e-03],\n         [ 8.34461538e-03],\n         [ 4.92332308e-02],\n         [ 7.55187692e-02],\n         [ 6.02898462e-02],\n         [ 2.08615385e-03],\n         [-4.90246154e-02],\n         [-4.65212308e-02],\n         [-3.54646154e-03],\n         [ 4.02627692e-02],\n         [ 4.54781538e-02],\n         [ 7.09292308e-03],\n         [-3.48387692e-02],\n         [-3.54646154e-02],\n         [-9.80492308e-03],\n         [ 9.59630769e-03],\n         [-7.09292308e-03],\n         [-4.48523077e-02],\n         [-5.27796923e-02],\n         [-1.91926154e-02],\n         [ 3.35870769e-02],\n         [ 5.19452308e-02],\n         [ 3.37956923e-02],\n         [ 1.46030769e-03],\n         [-1.46030769e-03],\n         [ 4.88160000e-02],\n         [ 7.98996923e-02],\n         [ 5.54916923e-02],\n         [-7.30153846e-03],\n         [-5.21538462e-02],\n         [-4.50609231e-02],\n         [-3.33784615e-03],\n         [ 4.96504615e-02],\n         [ 5.79950769e-02],\n         [ 2.08615385e-02],\n         [-1.08480000e-02],\n         [-1.02221538e-02],\n         [ 2.46166154e-02],\n         [ 3.56732308e-02],\n         [ 1.12652308e-02],\n         [-1.23083077e-02],\n         [-2.29476923e-02],\n         [ 1.27255385e-02],\n         [ 5.31969231e-02],\n         [ 5.84123077e-02],\n         [ 3.67163077e-02],\n         [-1.75236923e-02],\n         [-3.15009231e-02],\n         [ 6.25846154e-04],\n         [ 3.06664615e-02],\n         [ 3.08750769e-02],\n         [-1.87753846e-02],\n         [-3.67163077e-02],\n         [-8.34461538e-03],\n         [ 3.83852308e-02],\n         [ 7.76049231e-02],\n         [ 8.03169231e-02],\n         [ 6.52966154e-02],\n         [ 3.65076923e-02],\n         [ 4.10972308e-02],\n         [ 5.63261538e-02],\n         [ 4.98590769e-02],\n         [ 2.56596923e-02],\n         [-1.71064615e-02],\n         [-1.29341538e-02],\n         [ 1.52289231e-02],\n         [ 5.19452308e-02],\n         [ 8.34461538e-02],\n         [ 5.90381538e-02],\n         [ 4.15144615e-02],\n         [ 4.06800000e-02],\n         [ 5.75778462e-02],\n         [ 8.30289231e-02],\n         [ 6.36276923e-02],\n         [ 4.23489231e-02],\n         [ 3.29612308e-02],\n         [ 4.73556923e-02],\n         [ 8.78270769e-02],\n         [ 9.90923077e-02],\n         [ 5.92467692e-02],\n         [-8.55323077e-03],\n         [-3.46301538e-02],\n         [-1.50203077e-02],\n         [ 1.52289231e-02],\n         [ 4.02627692e-02],\n         [ 4.58953846e-02],\n         [ 5.11107692e-02],\n         [ 7.25981538e-02],\n         [ 1.06185231e-01],\n         [ 1.21831385e-01],\n         [ 9.78406154e-02],\n         [ 3.56732308e-02],\n         [-1.02221538e-02],\n         [ 2.29476923e-03],\n         [ 5.09021538e-02],\n         [ 9.97181538e-02],\n         [ 1.19119385e-01],\n         [ 1.05768000e-01],\n         [ 9.99267692e-02],\n         [ 1.13486769e-01],\n         [ 1.13278154e-01],\n         [ 9.53372308e-02],\n         [ 5.21538462e-02],\n         [ 1.60633846e-02],\n         [ 4.17230769e-03],\n         [ 2.27390769e-02],\n         [ 7.21809231e-02],\n         [ 8.07341538e-02],\n         [ 6.71741538e-02],\n         [ 6.78000000e-02],\n         [ 6.71741538e-02],\n         [ 8.78270769e-02],\n         [ 9.19993846e-02],\n         [ 5.06935385e-02],\n         [-4.38092308e-03],\n         [-4.96504615e-02],\n         [-6.15415385e-02],\n         [-3.33784615e-02],\n         [ 6.25846154e-04],\n         [ 2.12787692e-02],\n         [ 3.33784615e-02],\n         [ 3.56732308e-02],\n         [ 6.75913846e-02],\n         [ 9.53372308e-02],\n         [ 6.57138462e-02],\n         [-6.25846154e-03],\n         [-8.15686154e-02],\n         [-1.03056000e-01],\n         [-6.50880000e-02],\n         [-1.41858462e-02],\n         [ 1.25169231e-03],\n         [-2.08615385e-04],\n         [-4.38092308e-03],\n         [-5.21538462e-03],\n         [ 2.71200000e-03],\n         [-1.41858462e-02],\n         [-5.11107692e-02],\n         [-9.07476923e-02],\n         [-9.78406154e-02],\n         [-6.98861538e-02],\n         [-2.92061538e-02],\n         [ 1.25169231e-03],\n         [ 8.34461538e-04],\n         [-2.29476923e-03],\n         [ 1.66892308e-03],\n         [ 1.08480000e-02],\n         [ 9.38769231e-03],\n         [-2.10701538e-02],\n         [-6.50880000e-02],\n         [-9.09563077e-02],\n         [-7.48929231e-02],\n         [-2.27390769e-02],\n         [ 2.16960000e-02],\n         [ 2.21132308e-02],\n         [ 3.12923077e-03],\n         [-1.23083077e-02],\n         [-4.38092308e-03],\n         [ 2.67027692e-02],\n         [ 1.89840000e-02],\n         [-2.27390769e-02],\n         [-5.23624615e-02],\n         [-6.13329231e-02],\n         [-2.52424615e-02],\n         [ 3.10836923e-02],\n         [ 7.48929231e-02],\n         [ 9.11649231e-02],\n         [ 8.36547692e-02],\n         [ 8.82443077e-02],\n         [ 8.46978462e-02],\n         [ 6.59224615e-02],\n         [ 1.37686154e-02],\n         [-5.84123077e-02],\n         [-8.07341538e-02],\n         [-5.79950769e-02],\n         [ 7.09292308e-03],\n         [ 4.81901538e-02],\n         [ 3.54646154e-02],\n         [ 2.27390769e-02],\n         [ 1.41858462e-02],\n         [ 3.75507692e-02],\n         [ 4.54781538e-02],\n         [ 1.27255385e-02],\n         [-4.25575385e-02],\n         [-1.05768000e-01],\n         [-1.08688615e-01],\n         [-6.04984615e-02],\n         [ 9.59630769e-03],\n         [ 6.19587692e-02],\n         [ 6.09156923e-02],\n         [ 4.71470769e-02],\n         [ 2.64941538e-02],\n         [ 1.35600000e-02],\n         [-8.34461538e-03],\n         [-7.34326154e-02],\n         [-1.13695385e-01],\n         [-1.11817846e-01],\n         [-4.94418462e-02],\n         [ 4.25575385e-02],\n         [ 1.03890462e-01],\n         [ 1.16824615e-01],\n         [ 7.69790769e-02],\n         [ 6.98861538e-02],\n         [ 9.07476923e-02],\n         [ 1.06602462e-01],\n         [ 6.96775385e-02],\n         [-1.68978462e-02],\n         [-5.92467692e-02],\n         [-5.88295385e-02],\n         [ 4.58953846e-03],\n         [ 7.71876923e-02],\n         [ 9.32510769e-02],\n         [ 8.78270769e-02],\n         [ 8.53236923e-02],\n         [ 1.01387077e-01],\n         [ 9.90923077e-02],\n         [ 7.03033846e-02],\n         [ 2.35735385e-02],\n         [-3.23353846e-02],\n         [-5.27796923e-02],\n         [-1.04307692e-02],\n         [ 6.25846154e-02],\n         [ 9.95095385e-02],\n         [ 8.86615385e-02],\n         [ 7.13464615e-02],\n         [ 7.88566154e-02],\n         [ 7.84393846e-02],\n         [ 6.36276923e-02],\n         [ 1.85667692e-02],\n         [-6.73827692e-02],\n         [-1.18702154e-01],\n         [-9.88836923e-02],\n         [-2.77458462e-02],\n         [ 5.15280000e-02],\n         [ 1.00761231e-01],\n         [ 1.00135385e-01],\n         [ 7.48929231e-02],\n         [ 5.36141538e-02],\n         [ 2.56596923e-02],\n         [-3.21267692e-02],\n         [-1.15990154e-01],\n         [-1.73150769e-01],\n         [-1.51454769e-01],\n         [-6.27932308e-02],\n         [ 4.52695385e-02],\n         [ 1.27672615e-01],\n         [ 1.33096615e-01],\n         [ 8.78270769e-02],\n         [ 4.52695385e-02],\n         [ 2.81630769e-02],\n         [-2.50338462e-03],\n         [-8.19858462e-02],\n         [-1.50620308e-01],\n         [-1.65432000e-01],\n         [-1.17033231e-01],\n         [-3.56732308e-02],\n         [ 2.50338462e-02],\n         [ 4.15144615e-02],\n         [ 2.48252308e-02],\n         [ 1.46030769e-02],\n         [ 2.64941538e-02],\n         [ 3.46301538e-02],\n         [ 2.12787692e-02],\n         [-1.23083077e-02],\n         [-4.92332308e-02],\n         [-4.46436923e-02],\n         [ 0.00000000e+00],\n         [ 4.58953846e-02],\n         [ 6.07070769e-02],\n         [ 3.00406154e-02],\n         [ 1.41858462e-02],\n         [ 3.12923077e-02],\n         [ 4.77729231e-02],\n         [ 3.83852308e-02],\n         [-3.77593846e-02],\n         [-1.21831385e-01],\n         [-1.50620308e-01],\n         [-1.01595692e-01],\n         [-8.13600000e-03],\n         [ 4.42264615e-02],\n         [ 3.19181538e-02],\n         [-9.38769231e-03],\n         [-2.56596923e-02],\n         [-3.21267692e-02],\n         [-5.65347692e-02],\n         [-1.05350769e-01],\n         [-1.74819692e-01],\n         [-2.09658462e-01],\n         [-1.77948923e-01],\n         [-1.09940308e-01],\n         [-4.02627692e-02],\n         [-1.73150769e-02],\n         [-4.58953846e-02],\n         [-7.28067692e-02],\n         [-6.50880000e-02],\n         [-3.10836923e-02],\n         [-2.60769231e-02],\n         [-5.52830769e-02],\n         [-8.57409231e-02],\n         [-7.63532308e-02],\n         [-2.19046154e-02],\n         [ 2.12787692e-02],\n         [ 3.04578462e-02],\n         [-8.34461538e-03],\n         [-4.61040000e-02],\n         [-2.37821538e-02],\n         [ 1.96098462e-02],\n         [ 5.96640000e-02],\n         [ 4.65212308e-02],\n         [-2.39907692e-02],\n         [-7.98996923e-02],\n         [-7.76049231e-02],\n         [-1.41858462e-02],\n         [ 4.04713846e-02],\n         [ 4.71470769e-02],\n         [ 3.83852308e-02],\n         [ 5.61175385e-02],\n         [ 1.02221538e-01],\n         [ 1.34139692e-01],\n         [ 1.12026462e-01],\n         [ 2.85803077e-02],\n         [-6.57138462e-02],\n         [-9.88836923e-02],\n         [-6.11243077e-02],\n         [-7.09292308e-03],\n         [ 1.00135385e-02],\n         [-1.81495385e-02],\n         [-3.62990769e-02],\n         [-1.04307692e-02],\n         [ 3.00406154e-02],\n         [ 4.21403077e-02],\n         [ 6.25846154e-03],\n         [-4.17230769e-02],\n         [-4.38092308e-02],\n         [ 9.80492308e-03],\n         [ 8.44892308e-02],\n         [ 1.37268923e-01],\n         [ 1.15572923e-01],\n         [ 5.52830769e-02],\n         [ 1.12652308e-02],\n         [ 6.25846154e-03],\n         [ 3.04578462e-02],\n         [ 2.73286154e-02],\n         [ 2.08615385e-03],\n         [-1.29341538e-02],\n         [ 1.41858462e-02],\n         [ 7.69790769e-02],\n         [ 1.36434462e-01],\n         [ 1.51454769e-01],\n         [ 1.19328000e-01],\n         [ 9.72147692e-02],\n         [ 1.18076308e-01],\n         [ 1.71273231e-01],\n         [ 1.99227692e-01],\n         [ 1.67935385e-01],\n         [ 1.10983385e-01],\n         [ 8.30289231e-02],\n         [ 1.15155692e-01],\n         [ 1.66266462e-01],\n         [ 1.82538462e-01],\n         [ 1.53540923e-01],\n         [ 1.09523077e-01],\n         [ 1.08062769e-01],\n         [ 1.45196308e-01],\n         [ 1.59799385e-01],\n         [ 1.17241846e-01],\n         [ 2.71200000e-02],\n         [-2.75372308e-02],\n         [-6.25846154e-04],\n         [ 7.07206154e-02],\n         [ 1.40815385e-01],\n         [ 1.52915077e-01],\n         [ 1.22457231e-01],\n         [ 7.65618462e-02],\n         [ 5.15280000e-02],\n         [ 4.98590769e-02],\n         [ 1.73150769e-02],\n         [-2.94147692e-02],\n         [-7.98996923e-02],\n         [-9.36683077e-02],\n         [-4.06800000e-02],\n         [ 2.44080000e-02],\n         [ 5.38227692e-02],\n         [ 2.12787692e-02],\n         [-3.33784615e-02],\n         [-5.82036923e-02],\n         [-5.75778462e-02],\n         [-4.58953846e-02],\n         [-6.94689231e-02],\n         [-1.00552615e-01],\n         [-9.07476923e-02],\n         [-5.50744615e-02],\n         [ 1.08480000e-02],\n         [ 4.46436923e-02],\n         [ 3.04578462e-02],\n         [ 8.34461538e-04],\n         [-2.19046154e-02],\n         [ 1.46030769e-02],\n         [ 5.40313846e-02],\n         [ 4.79815385e-02],\n         [ 1.75236923e-02],\n         [-2.89975385e-02],\n         [-3.33784615e-02],\n         [ 1.18910769e-02],\n         [ 5.15280000e-02],\n         [ 6.17501538e-02],\n         [ 2.81630769e-02],\n         [ 6.88430769e-03],\n         [ 3.31698462e-02],\n         [ 7.38498462e-02],\n         [ 9.63803077e-02],\n         [ 6.48793846e-02],\n         [ 6.04984615e-03],\n         [-2.44080000e-02],\n         [-2.08615385e-03],\n         [ 4.75643077e-02],\n         [ 7.73963077e-02],\n         [ 6.30018462e-02],\n         [ 2.73286154e-02],\n         [ 1.50203077e-02],\n         [ 1.81495385e-02],\n         [ 2.29476923e-02],\n         [ 2.50338462e-03],\n         [-4.46436923e-02],\n         [-7.51015385e-02],\n         [-6.27932308e-02],\n         [-1.02221538e-02]]]])"
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.array(data.iloc[2,1:])\n",
    "a=a.reshape(1,1,2376,1)\n",
    "a"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "The new data point is predicted to be faulty.\n"
     ]
    }
   ],
   "source": [
    "s=model.predict(a)\n",
    "\n",
    "# Print the predicted class\n",
    "if s > 0.5:\n",
    "    print(\"The new data point is predicted to be faulty.\")\n",
    "else:\n",
    "    print(\"The new data point is predicted to be normal.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fault    0.000000\n",
      "0        0.000000\n",
      "1        0.064254\n",
      "2        0.063002\n",
      "3       -0.004381\n",
      "           ...   \n",
      "2371     0.002503\n",
      "2372    -0.044644\n",
      "2373    -0.075102\n",
      "2374    -0.062793\n",
      "2375    -0.010222\n",
      "Name: 2HP, Length: 2377, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(data.iloc[2])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
